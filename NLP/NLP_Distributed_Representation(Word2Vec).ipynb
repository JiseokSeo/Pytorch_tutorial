{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "지난번 빈도 기반 벡터화 방법을 공부했다.\n",
        "\n",
        "# 학습목표\n",
        "분산 기반 벡터화 방법(Word2Vec)을 케라스 모델에 임포팅할 수 있다.\n"
      ],
      "metadata": {
        "id": "otFjIDpHVQln"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "분산 기반 벡터화의 대표, Word2Vec은 target단어 주변 단어에 의해 표현이 결정된다.\n",
        "* Word2Vec의 벡터화 방법\n",
        "  1. CBow 방법  \n",
        "    문장에서 마스킹된 단어의 주변단어를 읽고 마스킹된 단어를 예측하는 과정\n",
        "\n",
        "  2. skip-gram 방법  \n",
        "    문장에서 표시된 단어를 읽고 마스킹된 주변 단어를 예측하는 과정\n",
        "    \n"
      ],
      "metadata": {
        "id": "KJ5WCKrzVfcy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### gensim 패키지로 구현하는 word2vec"
      ],
      "metadata": {
        "id": "utVi5RuQYJT1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9VzaHpXVGtx",
        "outputId": "a3e52a18-8f4c-44b1-98f6-db5688f6a5f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.8/dist-packages (4.3.0)\n",
            "Requirement already satisfied: FuzzyTM>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from gensim) (2.0.5)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (6.3.0)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: pyfume in /usr/local/lib/python3.8/dist-packages (from FuzzyTM>=0.4.0->gensim) (0.2.25)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from FuzzyTM>=0.4.0->gensim) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2022.7)\n",
            "Requirement already satisfied: fst-pso in /usr/local/lib/python3.8/dist-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (1.8.1)\n",
            "Requirement already satisfied: simpful in /usr/local/lib/python3.8/dist-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (2.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->FuzzyTM>=0.4.0->gensim) (1.15.0)\n",
            "Requirement already satisfied: miniful in /usr/local/lib/python3.8/dist-packages (from fst-pso->pyfume->FuzzyTM>=0.4.0->gensim) (0.0.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2.25.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (4.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.6)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.24.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scipy 1.7.3 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.24.1 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.1\n"
          ]
        }
      ],
      "source": [
        "# !pip install gensim --upgrade\n",
        "# !pip install --upgrade numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozYUabxpYQFj",
        "outputId": "123436a6-e07d-4f9a-e18d-6c6f51e106bd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gensim 디폴트 프리트레인 모델 불러오기 (구글 뉴스 말뭉치 학습 모델)\n",
        "import gensim.downloader as api\n",
        "wv = api.load('word2vec-google-news-300')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyUgRk4ZYR-5",
        "outputId": "32e66471-47b7-46e2-fad7-3fffde1e87e6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=================================================-] 99.9% 1661.9/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습된 king 이라는 단어의 벡터 확인\n",
        "print(wv['king'].shape)\n",
        "wv['king']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSC82uOKYwDw",
        "outputId": "aa8b49ff-c6d8-4bdf-a00b-cd9e6b5eff42"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(300,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.25976562e-01,  2.97851562e-02,  8.60595703e-03,  1.39648438e-01,\n",
              "       -2.56347656e-02, -3.61328125e-02,  1.11816406e-01, -1.98242188e-01,\n",
              "        5.12695312e-02,  3.63281250e-01, -2.42187500e-01, -3.02734375e-01,\n",
              "       -1.77734375e-01, -2.49023438e-02, -1.67968750e-01, -1.69921875e-01,\n",
              "        3.46679688e-02,  5.21850586e-03,  4.63867188e-02,  1.28906250e-01,\n",
              "        1.36718750e-01,  1.12792969e-01,  5.95703125e-02,  1.36718750e-01,\n",
              "        1.01074219e-01, -1.76757812e-01, -2.51953125e-01,  5.98144531e-02,\n",
              "        3.41796875e-01, -3.11279297e-02,  1.04492188e-01,  6.17675781e-02,\n",
              "        1.24511719e-01,  4.00390625e-01, -3.22265625e-01,  8.39843750e-02,\n",
              "        3.90625000e-02,  5.85937500e-03,  7.03125000e-02,  1.72851562e-01,\n",
              "        1.38671875e-01, -2.31445312e-01,  2.83203125e-01,  1.42578125e-01,\n",
              "        3.41796875e-01, -2.39257812e-02, -1.09863281e-01,  3.32031250e-02,\n",
              "       -5.46875000e-02,  1.53198242e-02, -1.62109375e-01,  1.58203125e-01,\n",
              "       -2.59765625e-01,  2.01416016e-02, -1.63085938e-01,  1.35803223e-03,\n",
              "       -1.44531250e-01, -5.68847656e-02,  4.29687500e-02, -2.46582031e-02,\n",
              "        1.85546875e-01,  4.47265625e-01,  9.58251953e-03,  1.31835938e-01,\n",
              "        9.86328125e-02, -1.85546875e-01, -1.00097656e-01, -1.33789062e-01,\n",
              "       -1.25000000e-01,  2.83203125e-01,  1.23046875e-01,  5.32226562e-02,\n",
              "       -1.77734375e-01,  8.59375000e-02, -2.18505859e-02,  2.05078125e-02,\n",
              "       -1.39648438e-01,  2.51464844e-02,  1.38671875e-01, -1.05468750e-01,\n",
              "        1.38671875e-01,  8.88671875e-02, -7.51953125e-02, -2.13623047e-02,\n",
              "        1.72851562e-01,  4.63867188e-02, -2.65625000e-01,  8.91113281e-03,\n",
              "        1.49414062e-01,  3.78417969e-02,  2.38281250e-01, -1.24511719e-01,\n",
              "       -2.17773438e-01, -1.81640625e-01,  2.97851562e-02,  5.71289062e-02,\n",
              "       -2.89306641e-02,  1.24511719e-02,  9.66796875e-02, -2.31445312e-01,\n",
              "        5.81054688e-02,  6.68945312e-02,  7.08007812e-02, -3.08593750e-01,\n",
              "       -2.14843750e-01,  1.45507812e-01, -4.27734375e-01, -9.39941406e-03,\n",
              "        1.54296875e-01, -7.66601562e-02,  2.89062500e-01,  2.77343750e-01,\n",
              "       -4.86373901e-04, -1.36718750e-01,  3.24218750e-01, -2.46093750e-01,\n",
              "       -3.03649902e-03, -2.11914062e-01,  1.25000000e-01,  2.69531250e-01,\n",
              "        2.04101562e-01,  8.25195312e-02, -2.01171875e-01, -1.60156250e-01,\n",
              "       -3.78417969e-02, -1.20117188e-01,  1.15234375e-01, -4.10156250e-02,\n",
              "       -3.95507812e-02, -8.98437500e-02,  6.34765625e-03,  2.03125000e-01,\n",
              "        1.86523438e-01,  2.73437500e-01,  6.29882812e-02,  1.41601562e-01,\n",
              "       -9.81445312e-02,  1.38671875e-01,  1.82617188e-01,  1.73828125e-01,\n",
              "        1.73828125e-01, -2.37304688e-01,  1.78710938e-01,  6.34765625e-02,\n",
              "        2.36328125e-01, -2.08984375e-01,  8.74023438e-02, -1.66015625e-01,\n",
              "       -7.91015625e-02,  2.43164062e-01, -8.88671875e-02,  1.26953125e-01,\n",
              "       -2.16796875e-01, -1.73828125e-01, -3.59375000e-01, -8.25195312e-02,\n",
              "       -6.49414062e-02,  5.07812500e-02,  1.35742188e-01, -7.47070312e-02,\n",
              "       -1.64062500e-01,  1.15356445e-02,  4.45312500e-01, -2.15820312e-01,\n",
              "       -1.11328125e-01, -1.92382812e-01,  1.70898438e-01, -1.25000000e-01,\n",
              "        2.65502930e-03,  1.92382812e-01, -1.74804688e-01,  1.39648438e-01,\n",
              "        2.92968750e-01,  1.13281250e-01,  5.95703125e-02, -6.39648438e-02,\n",
              "        9.96093750e-02, -2.72216797e-02,  1.96533203e-02,  4.27246094e-02,\n",
              "       -2.46093750e-01,  6.39648438e-02, -2.25585938e-01, -1.68945312e-01,\n",
              "        2.89916992e-03,  8.20312500e-02,  3.41796875e-01,  4.32128906e-02,\n",
              "        1.32812500e-01,  1.42578125e-01,  7.61718750e-02,  5.98144531e-02,\n",
              "       -1.19140625e-01,  2.74658203e-03, -6.29882812e-02, -2.72216797e-02,\n",
              "       -4.82177734e-03, -8.20312500e-02, -2.49023438e-02, -4.00390625e-01,\n",
              "       -1.06933594e-01,  4.24804688e-02,  7.76367188e-02, -1.16699219e-01,\n",
              "        7.37304688e-02, -9.22851562e-02,  1.07910156e-01,  1.58203125e-01,\n",
              "        4.24804688e-02,  1.26953125e-01,  3.61328125e-02,  2.67578125e-01,\n",
              "       -1.01074219e-01, -3.02734375e-01, -5.76171875e-02,  5.05371094e-02,\n",
              "        5.26428223e-04, -2.07031250e-01, -1.38671875e-01, -8.97216797e-03,\n",
              "       -2.78320312e-02, -1.41601562e-01,  2.07031250e-01, -1.58203125e-01,\n",
              "        1.27929688e-01,  1.49414062e-01, -2.24609375e-02, -8.44726562e-02,\n",
              "        1.22558594e-01,  2.15820312e-01, -2.13867188e-01, -3.12500000e-01,\n",
              "       -3.73046875e-01,  4.08935547e-03,  1.07421875e-01,  1.06933594e-01,\n",
              "        7.32421875e-02,  8.97216797e-03, -3.88183594e-02, -1.29882812e-01,\n",
              "        1.49414062e-01, -2.14843750e-01, -1.83868408e-03,  9.91210938e-02,\n",
              "        1.57226562e-01, -1.14257812e-01, -2.05078125e-01,  9.91210938e-02,\n",
              "        3.69140625e-01, -1.97265625e-01,  3.54003906e-02,  1.09375000e-01,\n",
              "        1.31835938e-01,  1.66992188e-01,  2.35351562e-01,  1.04980469e-01,\n",
              "       -4.96093750e-01, -1.64062500e-01, -1.56250000e-01, -5.22460938e-02,\n",
              "        1.03027344e-01,  2.43164062e-01, -1.88476562e-01,  5.07812500e-02,\n",
              "       -9.37500000e-02, -6.68945312e-02,  2.27050781e-02,  7.61718750e-02,\n",
              "        2.89062500e-01,  3.10546875e-01, -5.37109375e-02,  2.28515625e-01,\n",
              "        2.51464844e-02,  6.78710938e-02, -1.21093750e-01, -2.15820312e-01,\n",
              "       -2.73437500e-01, -3.07617188e-02, -3.37890625e-01,  1.53320312e-01,\n",
              "        2.33398438e-01, -2.08007812e-01,  3.73046875e-01,  8.20312500e-02,\n",
              "        2.51953125e-01, -7.61718750e-02, -4.66308594e-02, -2.23388672e-02,\n",
              "        2.99072266e-02, -5.93261719e-02, -4.66918945e-03, -2.44140625e-01,\n",
              "       -2.09960938e-01, -2.87109375e-01, -4.54101562e-02, -1.77734375e-01,\n",
              "       -2.79296875e-01, -8.59375000e-02,  9.13085938e-02,  2.51953125e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습되지 않은 'cameroon'이라는 단어의 벡터 확인\n",
        "try:\n",
        "  wv['cameroon']\n",
        "except:\n",
        "  print('해당 모델에 학습되지 않은 단어 ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNmBRDX2ZTV1",
        "outputId": "8d375872-f274-4708-8355-e61ada1674fb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "해당 모델에 학습되지 않은 단어 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 두 단어간 유사도 파악\n",
        "pairs = [\n",
        "    ('car', 'minivan'),   \n",
        "    ('car', 'bicycle'),  \n",
        "    ('car', 'airplane'),\n",
        "    ('car', 'cereal'),    \n",
        "    ('car', 'democracy')\n",
        "]\n",
        "\n",
        "for w1, w2 in pairs:\n",
        "    print(f'{w1} ======= {w2}\\t  {wv.similarity(w1, w2):.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtlcX-8KZqkt",
        "outputId": "2a1f57f1-0a08-4bdd-febd-79e269b3ab78"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "car ======= minivan\t  0.69\n",
            "car ======= bicycle\t  0.54\n",
            "car ======= airplane\t  0.42\n",
            "car ======= cereal\t  0.14\n",
            "car ======= democracy\t  0.08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 가장 잘 맞는 단어\n",
        "wv.most_similar('car',\n",
        "                topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2aR0JQbcPN3",
        "outputId": "e325907a-4647-4ce7-ea31-3f083b1d5279"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('vehicle', 0.7821096181869507),\n",
              " ('cars', 0.7423831224441528),\n",
              " ('SUV', 0.7160962224006653),\n",
              " ('minivan', 0.6907036900520325),\n",
              " ('truck', 0.6735789775848389),\n",
              " ('Car', 0.6677608489990234),\n",
              " ('Ford_Focus', 0.667320191860199),\n",
              " ('Honda_Civic', 0.6626849174499512),\n",
              " ('Jeep', 0.651133120059967),\n",
              " ('pickup_truck', 0.6441438794136047)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어 덩어리 중 가장 매치가 안되는 단어\n",
        "wv.doesnt_match(['fire', 'water', 'land', 'sea', 'air', 'car'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7Ox9XlCCcjBA",
        "outputId": "ae90df3b-35a5-4a34-da79-17762e18488b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'car'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 벡터의 합 positive 메서드\n",
        "for i, (word, similarity) in enumerate(wv.most_similar(positive=['coffe', 'sugar'], topn=5)):\n",
        "  print(f'top{i+1}: {word}, {similarity}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYN0Qsk6aL3-",
        "outputId": "caac4b0d-49c8-4297-867d-4fe3a543e00a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "top1: coffee, 0.6647744178771973\n",
            "top2: suger, 0.6409335136413574\n",
            "top3: turbinado, 0.6205686926841736\n",
            "top4: strawberry_smoothie, 0.6185998916625977\n",
            "top5: HobNobs, 0.613012969493866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 벡터의 차 negative\n",
        "wv.most_similar(positive=['king', 'women'], negative=['men'], topn=1) # king + women - men"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8YOayygcCtt",
        "outputId": "3fed4d99-2363-41ed-fb36-ecc291b0e7fa"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.6525818109512329)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### gensim 문장 분류기\n",
        "\n",
        "문장의 벡터 = 문장을 이루는 모든 벡터값의 평균 벡터"
      ],
      "metadata": {
        "id": "l-ykAxY7dclC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.datasets import imdb"
      ],
      "metadata": {
        "id": "bouccdkjcxKt"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터셋 불러오기 "
      ],
      "metadata": {
        "id": "V5QS5vXDdyNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "iGjLtIkKdfqS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=20000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nxxAOA-dt1v",
        "outputId": "b182fff0-9c97-4c70-95e3-951d3bce8a7e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZBNiFqo1iMS",
        "outputId": "9948c66f-3c26-4183-eb63-ff5afce74a55"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train set shape : {X_train.shape}\")\n",
        "print(f\"Test set shape : {X_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2W6OOZ8Kdvwq",
        "outputId": "02b8ef5d-33e5-4e89-f2e4-160222dc58c4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set shape : (25000,)\n",
            "Test set shape : (25000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0][:10] # 인코딩 되어있다"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrq6k5dcdxl4",
        "outputId": "cf99a1e7-ec1e-4957-9819-ced50d27c04b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 디코딩 함수 \n",
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "    \"\"\"\n",
        "    word_index 를 받아서 text 를 sequence 형태로 반환하는 함수입니다.\n",
        "\n",
        "    Args:\n",
        "        text: 텍스트 시퀀스입니다 -> str\n",
        "    \"\"\"\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyZTK5xyhrcX",
        "outputId": "7215214a-0077-4dec-e4a4-46372b4e6b15"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1641221/1641221 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decode_review(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "_D03DO8Dh7Be",
        "outputId": "0124efad-a598-4634-d4fc-3a9382c600cd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but pratfalls to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other tricky in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of 'n odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 토크나이징 "
      ],
      "metadata": {
        "id": "7DgUOMzliO14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습데이터 디코딩\n",
        "sentences = [decode_review(idx) for idx in X_train]\n",
        "\n",
        "# 케라스 토크나이저 선언\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# 케라스 토크나이저 학습\n",
        "tokenizer.fit_on_texts(sentences)"
      ],
      "metadata": {
        "id": "2MC4OXIvh8gA"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어사전 확인\n",
        "# tokenizer.word_index"
      ],
      "metadata": {
        "id": "ifI4H6lWtqsw"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 토크나이징\n",
        "X_encoded = tokenizer.texts_to_sequences(sentences)"
      ],
      "metadata": {
        "id": "wGlQbBiQun3M"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 토크나이징 결과 확인\n",
        "X_encoded[0][:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AthP7zGnu2ao",
        "outputId": "e63576ed-b28e-4409-92e8-5d9d8c1b2e3d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[30, 12, 20, 14, 42, 528, 970, 1620, 1383, 64]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 패딩\n",
        "print(f'학습데이터 평균 길이: {np.mean([len(i) for i in X_train])}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN19u_ZTu3uT",
        "outputId": "09c4ead2-3dd9-4954-ba52-4d7438080961"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습데이터 평균 길이: 238.71364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 패딩 길이 설정\n",
        "maxlen_pad = 400\n",
        "\n",
        "# 패딩\n",
        "X_train=pad_sequences(X_encoded, maxlen=maxlen_pad, padding='post')\n",
        "\n",
        "# 타겟 벡터화\n",
        "y_train=np.array(y_train)"
      ],
      "metadata": {
        "id": "S1SuBUHtwLd9"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 단어사전에 있는 단어의 가중치만 가져오기 "
      ],
      "metadata": {
        "id": "jMHI8vJJy7K3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1 # 패딩 1\n",
        "embedding_matrix = np.zeros((vocab_size, 300))"
      ],
      "metadata": {
        "id": "2LEczXmCwbIN"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어사전에 등재된 가중치만 가져와서 embedding_matrix로 저장\n",
        "def get_vector(word):\n",
        "    \"\"\"\n",
        "    입력 단어가 vocab 에 있는 단어일 경우 임베딩 벡터를 반환\n",
        "    \n",
        "    Args:\n",
        "        word: 입력 단어 -> str\n",
        "    \"\"\"\n",
        "    if word in wv:\n",
        "        return wv[word]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    temp = get_vector(word)\n",
        "    if temp is not None:\n",
        "        embedding_matrix[i] = temp"
      ],
      "metadata": {
        "id": "_fxgp8BPzDdw"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gs6jnUPFzPW6",
        "outputId": "bc88e19d-aa26-4c40-d8a0-060d5b70f717"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       ...,\n",
              "       [ 0.09082031, -0.21777344, -0.07226562, ...,  0.32226562,\n",
              "        -0.05957031, -0.11328125],\n",
              "       [-0.265625  ,  0.25585938, -0.01855469, ...,  0.0480957 ,\n",
              "         0.34765625,  0.01177979],\n",
              "       [-0.05541992,  0.26367188,  0.18457031, ..., -0.16503906,\n",
              "        -0.25976562, -0.14257812]])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 가중치를 케라스 모델에 적용하여 문장 분류기 만들기 "
      ],
      "metadata": {
        "id": "saNgBSvI1Mju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten"
      ],
      "metadata": {
        "id": "Qa_-Tu9czUFg"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 생성\n",
        "model = Sequential()\n",
        "\n",
        "# 임베딩 층 추가\n",
        "model.add(Embedding(vocab_size, 300,\n",
        "                    weights=[embedding_matrix],\n",
        "                    input_length=maxlen_pad,\n",
        "                    trainable=False)) # 파인튜닝X 전이학습O\n",
        "model.add(GlobalAveragePooling1D()) # 입력되는 단어 벡터의 평균을 구하는 레이어\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "I_nBW0Nl2f8e"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])"
      ],
      "metadata": {
        "id": "PAFgpeMX20t5"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, batch_size=64, epochs=20, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMK7WEJG26VN",
        "outputId": "2ca3e85d-feed-4cd2-f0e2-9773c00b43bf"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "313/313 [==============================] - 7s 20ms/step - loss: 0.6924 - acc: 0.5268 - val_loss: 0.6907 - val_acc: 0.5998\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.6901 - acc: 0.5767 - val_loss: 0.6882 - val_acc: 0.5972\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.6880 - acc: 0.5899 - val_loss: 0.6859 - val_acc: 0.6006\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 0.6861 - acc: 0.5918 - val_loss: 0.6837 - val_acc: 0.5928\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 7s 21ms/step - loss: 0.6845 - acc: 0.5949 - val_loss: 0.6824 - val_acc: 0.5970\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.6827 - acc: 0.5957 - val_loss: 0.6800 - val_acc: 0.5946\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.6813 - acc: 0.6028 - val_loss: 0.6787 - val_acc: 0.6112\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.6798 - acc: 0.6058 - val_loss: 0.6774 - val_acc: 0.6092\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.6784 - acc: 0.6048 - val_loss: 0.6755 - val_acc: 0.6150\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.6772 - acc: 0.6078 - val_loss: 0.6742 - val_acc: 0.6168\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.6759 - acc: 0.6100 - val_loss: 0.6730 - val_acc: 0.6172\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.6748 - acc: 0.6116 - val_loss: 0.6716 - val_acc: 0.6192\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 0.6736 - acc: 0.6095 - val_loss: 0.6712 - val_acc: 0.6128\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.6725 - acc: 0.6135 - val_loss: 0.6690 - val_acc: 0.6246\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.6712 - acc: 0.6158 - val_loss: 0.6679 - val_acc: 0.6212\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.6704 - acc: 0.6147 - val_loss: 0.6673 - val_acc: 0.6222\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.6693 - acc: 0.6191 - val_loss: 0.6670 - val_acc: 0.6196\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 0.6684 - acc: 0.6217 - val_loss: 0.6649 - val_acc: 0.6268\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.6674 - acc: 0.6205 - val_loss: 0.6641 - val_acc: 0.6266\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.6666 - acc: 0.6248 - val_loss: 0.6633 - val_acc: 0.6274\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa99d947190>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 데이터도 같은 절차\n",
        "test_sentences = [decode_review(idx) for idx in X_test]\n",
        "\n",
        "X_test_encoded = tokenizer.texts_to_sequences(test_sentences)\n",
        "\n",
        "X_test=pad_sequences(X_test_encoded, maxlen=400, padding='post')\n",
        "y_test=np.array(y_test)"
      ],
      "metadata": {
        "id": "a9ygiEcX28Fe"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HlrORVq3BSE",
        "outputId": "fdfeb4c4-6fa0-4f4e-9358-49b7a8c32a46"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 7s 9ms/step - loss: 0.6680 - acc: 0.6093\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6679654121398926, 0.609279990196228]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    }
  ]
}