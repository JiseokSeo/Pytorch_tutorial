{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 파이토치 미니 프로젝트: 보스턴 집값 예측\n",
        "유명한 데이터셋인 보스턴 집값 데이터셋으로 배운 것들을 활용해보겠습니다.\n",
        "\n",
        "1. 파이토치 모델 선언\n",
        "2. 가중치 초기화\n",
        "3. 과적합 방지기술 3종 "
      ],
      "metadata": {
        "id": "Ku-vP5RlWT8B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 360,
      "metadata": {
        "id": "qgfyLzKjWMWQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 임포트\n",
        "from sklearn.datasets import load_boston\n",
        "df = load_boston()\n",
        "X_train = pd.DataFrame(df['data'], columns=df['feature_names'])\n",
        "y_train = pd.DataFrame(df['target'], columns=['target'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OfNIXVvWmPQ",
        "outputId": "48c27d07-c80a-420f-cd34-11880f18e7a3"
      },
      "execution_count": 361,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "gtQsHV94YYs9",
        "outputId": "23052198-1c30-499f-a423-78ea58e36b14"
      },
      "execution_count": 362,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
              "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
              "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
              "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
              "\n",
              "   PTRATIO       B  LSTAT  \n",
              "0     15.3  396.90   4.98  \n",
              "1     17.8  396.90   9.14  \n",
              "2     17.8  392.83   4.03  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32a391e4-d0a6-4889-9463-ec765dae3e63\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32a391e4-d0a6-4889-9463-ec765dae3e63')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-32a391e4-d0a6-4889-9463-ec765dae3e63 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-32a391e4-d0a6-4889-9463-ec765dae3e63');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 362
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "g7jTJcsaYaMG",
        "outputId": "0499bce6-3861-44f4-97b4-b214a71c873f"
      },
      "execution_count": 363,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   target\n",
              "0    24.0\n",
              "1    21.6\n",
              "2    34.7"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-774681d5-1d4d-4ef2-b9f8-df8741e13903\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>34.7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-774681d5-1d4d-4ef2-b9f8-df8741e13903')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-774681d5-1d4d-4ef2-b9f8-df8741e13903 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-774681d5-1d4d-4ef2-b9f8-df8741e13903');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 363
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train,\n",
        "                                                    test_size=0.1)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train,\n",
        "                                                      test_size=0.2)"
      ],
      "metadata": {
        "id": "MWCB8TX3W3cB"
      },
      "execution_count": 364,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.Tensor(X_train.values)\n",
        "X_valid = torch.Tensor(X_valid.values)\n",
        "X_test = torch.Tensor(X_test.values)\n",
        "y_train = torch.Tensor(y_train.values)\n",
        "y_valid = torch.Tensor(y_valid.values)\n",
        "y_test = torch.Tensor(y_test.values)"
      ],
      "metadata": {
        "id": "kLBZztYodzPW"
      },
      "execution_count": 365,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3R9mnrWXJVA",
        "outputId": "2bef0e92-d7d2-4cc6-f751-448023ebd02d"
      },
      "execution_count": 366,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([364, 13]), torch.Size([364, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 366
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Linear(13, 32)    \n",
        "    )\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Linear(32, 16)\n",
        "    )\n",
        "    self.layer3 = nn.Sequential(\n",
        "        nn.Linear(16, 1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.layer3(x)\n",
        "    return x\n",
        "\n",
        "  def weight_initialization(self):\n",
        "    self.layer1[0].weight.data = nn.init.kaiming_uniform_(self.layer1[0].weight.data)\n",
        "    self.layer2[0].weight.data = nn.init.kaiming_uniform_(self.layer2[0].weight.data)"
      ],
      "metadata": {
        "id": "96fX_-v6ZFR7"
      },
      "execution_count": 367,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model()"
      ],
      "metadata": {
        "id": "wldMNlNKbKFz"
      },
      "execution_count": 368,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.weight_initialization()"
      ],
      "metadata": {
        "id": "ytaIWJ_HgM53"
      },
      "execution_count": 369,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXhFmwIegP2r",
        "outputId": "60871666-0479-408a-e9f6-e463b138d4c4"
      },
      "execution_count": 370,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (layer1): Sequential(\n",
              "    (0): Linear(in_features=13, out_features=32, bias=True)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Linear(in_features=32, out_features=16, bias=True)\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Linear(in_features=16, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 370
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=1000\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "4tqi8AcRc2Kh"
      },
      "execution_count": 371,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  prediction = model(X_train)\n",
        "  loss = F.mse_loss(prediction, y_train)\n",
        "  # early_stop.step(loss.item())\n",
        "  # if early_stop.is_stop():\n",
        "  #   break\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  print(f'epoch: {epoch:4d}/{epochs}  loss: {loss.item():.6f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2nqmhRRdEEA",
        "outputId": "d112e577-570c-4a9b-99c5-2bbcf8061cb6"
      },
      "execution_count": 372,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:    0/1000  loss: 932.285217\n",
            "epoch:    1/1000  loss: 26983.765625\n",
            "epoch:    2/1000  loss: 2004.777954\n",
            "epoch:    3/1000  loss: 5632.539551\n",
            "epoch:    4/1000  loss: 13666.547852\n",
            "epoch:    5/1000  loss: 9625.527344\n",
            "epoch:    6/1000  loss: 2700.078613\n",
            "epoch:    7/1000  loss: 109.267265\n",
            "epoch:    8/1000  loss: 2096.355469\n",
            "epoch:    9/1000  loss: 4852.842285\n",
            "epoch:   10/1000  loss: 5339.650879\n",
            "epoch:   11/1000  loss: 3570.031494\n",
            "epoch:   12/1000  loss: 1309.992920\n",
            "epoch:   13/1000  loss: 124.192322\n",
            "epoch:   14/1000  loss: 421.121918\n",
            "epoch:   15/1000  loss: 1518.475952\n",
            "epoch:   16/1000  loss: 2364.759766\n",
            "epoch:   17/1000  loss: 2347.887451\n",
            "epoch:   18/1000  loss: 1594.168945\n",
            "epoch:   19/1000  loss: 675.949097\n",
            "epoch:   20/1000  loss: 130.004974\n",
            "epoch:   21/1000  loss: 147.679108\n",
            "epoch:   22/1000  loss: 547.533936\n",
            "epoch:   23/1000  loss: 965.517090\n",
            "epoch:   24/1000  loss: 1109.308350\n",
            "epoch:   25/1000  loss: 915.417480\n",
            "epoch:   26/1000  loss: 535.377075\n",
            "epoch:   27/1000  loss: 200.043716\n",
            "epoch:   28/1000  loss: 70.404633\n",
            "epoch:   29/1000  loss: 160.255402\n",
            "epoch:   30/1000  loss: 356.731262\n",
            "epoch:   31/1000  loss: 508.602814\n",
            "epoch:   32/1000  loss: 520.583435\n",
            "epoch:   33/1000  loss: 397.910889\n",
            "epoch:   34/1000  loss: 224.219055\n",
            "epoch:   35/1000  loss: 98.443695\n",
            "epoch:   36/1000  loss: 74.790161\n",
            "epoch:   37/1000  loss: 139.106384\n",
            "epoch:   38/1000  loss: 228.803528\n",
            "epoch:   39/1000  loss: 277.972595\n",
            "epoch:   40/1000  loss: 257.231415\n",
            "epoch:   41/1000  loss: 185.100861\n",
            "epoch:   42/1000  loss: 108.550339\n",
            "epoch:   43/1000  loss: 69.628914\n",
            "epoch:   44/1000  loss: 80.678986\n",
            "epoch:   45/1000  loss: 121.716583\n",
            "epoch:   46/1000  loss: 158.060562\n",
            "epoch:   47/1000  loss: 164.260529\n",
            "epoch:   48/1000  loss: 138.459213\n",
            "epoch:   49/1000  loss: 99.610962\n",
            "epoch:   50/1000  loss: 71.987564\n",
            "epoch:   51/1000  loss: 68.793678\n",
            "epoch:   52/1000  loss: 85.483971\n",
            "epoch:   53/1000  loss: 105.589394\n",
            "epoch:   54/1000  loss: 113.401054\n",
            "epoch:   55/1000  loss: 104.161827\n",
            "epoch:   56/1000  loss: 85.393913\n",
            "epoch:   57/1000  loss: 69.835838\n",
            "epoch:   58/1000  loss: 66.027603\n",
            "epoch:   59/1000  loss: 73.240334\n",
            "epoch:   60/1000  loss: 83.494926\n",
            "epoch:   61/1000  loss: 88.196640\n",
            "epoch:   62/1000  loss: 84.133301\n",
            "epoch:   63/1000  loss: 74.798622\n",
            "epoch:   64/1000  loss: 66.842728\n",
            "epoch:   65/1000  loss: 64.879868\n",
            "epoch:   66/1000  loss: 68.556511\n",
            "epoch:   67/1000  loss: 73.612511\n",
            "epoch:   68/1000  loss: 75.573067\n",
            "epoch:   69/1000  loss: 73.013191\n",
            "epoch:   70/1000  loss: 68.087738\n",
            "epoch:   71/1000  loss: 64.358482\n",
            "epoch:   72/1000  loss: 63.932514\n",
            "epoch:   73/1000  loss: 66.138046\n",
            "epoch:   74/1000  loss: 68.483757\n",
            "epoch:   75/1000  loss: 68.828293\n",
            "epoch:   76/1000  loss: 66.937119\n",
            "epoch:   77/1000  loss: 64.340706\n",
            "epoch:   78/1000  loss: 62.866611\n",
            "epoch:   79/1000  loss: 63.180847\n",
            "epoch:   80/1000  loss: 64.463608\n",
            "epoch:   81/1000  loss: 65.295776\n",
            "epoch:   82/1000  loss: 64.871864\n",
            "epoch:   83/1000  loss: 63.532085\n",
            "epoch:   84/1000  loss: 62.298656\n",
            "epoch:   85/1000  loss: 61.943150\n",
            "epoch:   86/1000  loss: 62.408272\n",
            "epoch:   87/1000  loss: 62.993179\n",
            "epoch:   88/1000  loss: 63.030090\n",
            "epoch:   89/1000  loss: 62.423393\n",
            "epoch:   90/1000  loss: 61.630268\n",
            "epoch:   91/1000  loss: 61.189194\n",
            "epoch:   92/1000  loss: 61.258125\n",
            "epoch:   93/1000  loss: 61.546768\n",
            "epoch:   94/1000  loss: 61.635769\n",
            "epoch:   95/1000  loss: 61.352688\n",
            "epoch:   96/1000  loss: 60.876297\n",
            "epoch:   97/1000  loss: 60.523659\n",
            "epoch:   98/1000  loss: 60.454182\n",
            "epoch:   99/1000  loss: 60.558788\n",
            "epoch:  100/1000  loss: 60.599743\n",
            "epoch:  101/1000  loss: 60.439785\n",
            "epoch:  102/1000  loss: 60.144928\n",
            "epoch:  103/1000  loss: 59.891193\n",
            "epoch:  104/1000  loss: 59.789856\n",
            "epoch:  105/1000  loss: 59.799274\n",
            "epoch:  106/1000  loss: 59.788353\n",
            "epoch:  107/1000  loss: 59.669529\n",
            "epoch:  108/1000  loss: 59.470219\n",
            "epoch:  109/1000  loss: 59.288151\n",
            "epoch:  110/1000  loss: 59.189919\n",
            "epoch:  111/1000  loss: 59.155392\n",
            "epoch:  112/1000  loss: 59.110989\n",
            "epoch:  113/1000  loss: 59.006805\n",
            "epoch:  114/1000  loss: 58.858936\n",
            "epoch:  115/1000  loss: 58.722771\n",
            "epoch:  116/1000  loss: 58.634357\n",
            "epoch:  117/1000  loss: 58.579590\n",
            "epoch:  118/1000  loss: 58.516323\n",
            "epoch:  119/1000  loss: 58.419147\n",
            "epoch:  120/1000  loss: 58.300743\n",
            "epoch:  121/1000  loss: 58.193027\n",
            "epoch:  122/1000  loss: 58.113087\n",
            "epoch:  123/1000  loss: 58.049091\n",
            "epoch:  124/1000  loss: 57.976921\n",
            "epoch:  125/1000  loss: 57.885635\n",
            "epoch:  126/1000  loss: 57.785957\n",
            "epoch:  127/1000  loss: 57.695869\n",
            "epoch:  128/1000  loss: 57.621555\n",
            "epoch:  129/1000  loss: 57.553303\n",
            "epoch:  130/1000  loss: 57.477871\n",
            "epoch:  131/1000  loss: 57.392437\n",
            "epoch:  132/1000  loss: 57.305470\n",
            "epoch:  133/1000  loss: 57.226311\n",
            "epoch:  134/1000  loss: 57.155441\n",
            "epoch:  135/1000  loss: 57.085506\n",
            "epoch:  136/1000  loss: 57.010281\n",
            "epoch:  137/1000  loss: 56.930729\n",
            "epoch:  138/1000  loss: 56.852768\n",
            "epoch:  139/1000  loss: 56.780220\n",
            "epoch:  140/1000  loss: 56.711338\n",
            "epoch:  141/1000  loss: 56.641354\n",
            "epoch:  142/1000  loss: 56.568211\n",
            "epoch:  143/1000  loss: 56.494083\n",
            "epoch:  144/1000  loss: 56.422337\n",
            "epoch:  145/1000  loss: 56.353809\n",
            "epoch:  146/1000  loss: 56.286274\n",
            "epoch:  147/1000  loss: 56.217419\n",
            "epoch:  148/1000  loss: 56.147213\n",
            "epoch:  149/1000  loss: 56.077621\n",
            "epoch:  150/1000  loss: 56.010086\n",
            "epoch:  151/1000  loss: 55.944016\n",
            "epoch:  152/1000  loss: 55.877808\n",
            "epoch:  153/1000  loss: 55.810772\n",
            "epoch:  154/1000  loss: 55.743641\n",
            "epoch:  155/1000  loss: 55.677612\n",
            "epoch:  156/1000  loss: 55.612846\n",
            "epoch:  157/1000  loss: 55.548405\n",
            "epoch:  158/1000  loss: 55.483700\n",
            "epoch:  159/1000  loss: 55.418804\n",
            "epoch:  160/1000  loss: 55.354416\n",
            "epoch:  161/1000  loss: 55.290909\n",
            "epoch:  162/1000  loss: 55.227978\n",
            "epoch:  163/1000  loss: 55.164986\n",
            "epoch:  164/1000  loss: 55.101948\n",
            "epoch:  165/1000  loss: 55.039143\n",
            "epoch:  166/1000  loss: 54.976917\n",
            "epoch:  167/1000  loss: 54.915161\n",
            "epoch:  168/1000  loss: 54.853622\n",
            "epoch:  169/1000  loss: 54.792057\n",
            "epoch:  170/1000  loss: 54.730614\n",
            "epoch:  171/1000  loss: 54.669582\n",
            "epoch:  172/1000  loss: 54.608963\n",
            "epoch:  173/1000  loss: 54.548542\n",
            "epoch:  174/1000  loss: 54.488186\n",
            "epoch:  175/1000  loss: 54.427982\n",
            "epoch:  176/1000  loss: 54.368015\n",
            "epoch:  177/1000  loss: 54.308384\n",
            "epoch:  178/1000  loss: 54.248959\n",
            "epoch:  179/1000  loss: 54.189629\n",
            "epoch:  180/1000  loss: 54.130398\n",
            "epoch:  181/1000  loss: 54.071404\n",
            "epoch:  182/1000  loss: 54.012653\n",
            "epoch:  183/1000  loss: 53.954060\n",
            "epoch:  184/1000  loss: 53.895599\n",
            "epoch:  185/1000  loss: 53.837273\n",
            "epoch:  186/1000  loss: 53.779102\n",
            "epoch:  187/1000  loss: 53.721077\n",
            "epoch:  188/1000  loss: 53.663288\n",
            "epoch:  189/1000  loss: 53.605564\n",
            "epoch:  190/1000  loss: 53.548000\n",
            "epoch:  191/1000  loss: 53.490555\n",
            "epoch:  192/1000  loss: 53.433235\n",
            "epoch:  193/1000  loss: 53.376099\n",
            "epoch:  194/1000  loss: 53.319016\n",
            "epoch:  195/1000  loss: 53.262085\n",
            "epoch:  196/1000  loss: 53.205265\n",
            "epoch:  197/1000  loss: 53.148598\n",
            "epoch:  198/1000  loss: 53.091972\n",
            "epoch:  199/1000  loss: 53.035568\n",
            "epoch:  200/1000  loss: 52.979206\n",
            "epoch:  201/1000  loss: 52.922947\n",
            "epoch:  202/1000  loss: 52.866814\n",
            "epoch:  203/1000  loss: 52.810749\n",
            "epoch:  204/1000  loss: 52.754852\n",
            "epoch:  205/1000  loss: 52.699036\n",
            "epoch:  206/1000  loss: 52.643253\n",
            "epoch:  207/1000  loss: 52.587643\n",
            "epoch:  208/1000  loss: 52.532108\n",
            "epoch:  209/1000  loss: 52.476669\n",
            "epoch:  210/1000  loss: 52.421291\n",
            "epoch:  211/1000  loss: 52.366035\n",
            "epoch:  212/1000  loss: 52.310825\n",
            "epoch:  213/1000  loss: 52.255768\n",
            "epoch:  214/1000  loss: 52.200760\n",
            "epoch:  215/1000  loss: 52.145851\n",
            "epoch:  216/1000  loss: 52.091019\n",
            "epoch:  217/1000  loss: 52.036327\n",
            "epoch:  218/1000  loss: 51.981647\n",
            "epoch:  219/1000  loss: 51.927063\n",
            "epoch:  220/1000  loss: 51.872562\n",
            "epoch:  221/1000  loss: 51.818176\n",
            "epoch:  222/1000  loss: 51.763866\n",
            "epoch:  223/1000  loss: 51.709614\n",
            "epoch:  224/1000  loss: 51.655449\n",
            "epoch:  225/1000  loss: 51.601341\n",
            "epoch:  226/1000  loss: 51.547363\n",
            "epoch:  227/1000  loss: 51.493450\n",
            "epoch:  228/1000  loss: 51.439575\n",
            "epoch:  229/1000  loss: 51.385830\n",
            "epoch:  230/1000  loss: 51.332161\n",
            "epoch:  231/1000  loss: 51.278534\n",
            "epoch:  232/1000  loss: 51.225021\n",
            "epoch:  233/1000  loss: 51.171574\n",
            "epoch:  234/1000  loss: 51.118202\n",
            "epoch:  235/1000  loss: 51.064899\n",
            "epoch:  236/1000  loss: 51.011692\n",
            "epoch:  237/1000  loss: 50.958572\n",
            "epoch:  238/1000  loss: 50.905495\n",
            "epoch:  239/1000  loss: 50.852539\n",
            "epoch:  240/1000  loss: 50.799656\n",
            "epoch:  241/1000  loss: 50.746849\n",
            "epoch:  242/1000  loss: 50.694050\n",
            "epoch:  243/1000  loss: 50.641472\n",
            "epoch:  244/1000  loss: 50.588879\n",
            "epoch:  245/1000  loss: 50.536392\n",
            "epoch:  246/1000  loss: 50.483955\n",
            "epoch:  247/1000  loss: 50.431637\n",
            "epoch:  248/1000  loss: 50.379356\n",
            "epoch:  249/1000  loss: 50.327206\n",
            "epoch:  250/1000  loss: 50.275089\n",
            "epoch:  251/1000  loss: 50.223129\n",
            "epoch:  252/1000  loss: 50.171162\n",
            "epoch:  253/1000  loss: 50.119335\n",
            "epoch:  254/1000  loss: 50.067581\n",
            "epoch:  255/1000  loss: 50.015915\n",
            "epoch:  256/1000  loss: 49.964298\n",
            "epoch:  257/1000  loss: 49.912811\n",
            "epoch:  258/1000  loss: 49.861370\n",
            "epoch:  259/1000  loss: 49.810043\n",
            "epoch:  260/1000  loss: 49.758747\n",
            "epoch:  261/1000  loss: 49.707607\n",
            "epoch:  262/1000  loss: 49.656517\n",
            "epoch:  263/1000  loss: 49.605499\n",
            "epoch:  264/1000  loss: 49.554646\n",
            "epoch:  265/1000  loss: 49.503799\n",
            "epoch:  266/1000  loss: 49.453056\n",
            "epoch:  267/1000  loss: 49.402409\n",
            "epoch:  268/1000  loss: 49.351837\n",
            "epoch:  269/1000  loss: 49.301376\n",
            "epoch:  270/1000  loss: 49.250999\n",
            "epoch:  271/1000  loss: 49.200699\n",
            "epoch:  272/1000  loss: 49.150494\n",
            "epoch:  273/1000  loss: 49.100426\n",
            "epoch:  274/1000  loss: 49.050346\n",
            "epoch:  275/1000  loss: 49.000446\n",
            "epoch:  276/1000  loss: 48.950634\n",
            "epoch:  277/1000  loss: 48.900890\n",
            "epoch:  278/1000  loss: 48.851192\n",
            "epoch:  279/1000  loss: 48.801640\n",
            "epoch:  280/1000  loss: 48.752167\n",
            "epoch:  281/1000  loss: 48.702847\n",
            "epoch:  282/1000  loss: 48.653507\n",
            "epoch:  283/1000  loss: 48.604370\n",
            "epoch:  284/1000  loss: 48.555279\n",
            "epoch:  285/1000  loss: 48.506279\n",
            "epoch:  286/1000  loss: 48.457386\n",
            "epoch:  287/1000  loss: 48.408596\n",
            "epoch:  288/1000  loss: 48.359879\n",
            "epoch:  289/1000  loss: 48.311275\n",
            "epoch:  290/1000  loss: 48.262775\n",
            "epoch:  291/1000  loss: 48.214382\n",
            "epoch:  292/1000  loss: 48.166080\n",
            "epoch:  293/1000  loss: 48.117863\n",
            "epoch:  294/1000  loss: 48.069721\n",
            "epoch:  295/1000  loss: 48.021721\n",
            "epoch:  296/1000  loss: 47.973835\n",
            "epoch:  297/1000  loss: 47.925991\n",
            "epoch:  298/1000  loss: 47.878296\n",
            "epoch:  299/1000  loss: 47.830654\n",
            "epoch:  300/1000  loss: 47.783161\n",
            "epoch:  301/1000  loss: 47.735733\n",
            "epoch:  302/1000  loss: 47.688438\n",
            "epoch:  303/1000  loss: 47.641232\n",
            "epoch:  304/1000  loss: 47.594151\n",
            "epoch:  305/1000  loss: 47.547104\n",
            "epoch:  306/1000  loss: 47.500229\n",
            "epoch:  307/1000  loss: 47.453445\n",
            "epoch:  308/1000  loss: 47.406727\n",
            "epoch:  309/1000  loss: 47.360184\n",
            "epoch:  310/1000  loss: 47.313633\n",
            "epoch:  311/1000  loss: 47.267292\n",
            "epoch:  312/1000  loss: 47.221020\n",
            "epoch:  313/1000  loss: 47.174835\n",
            "epoch:  314/1000  loss: 47.128784\n",
            "epoch:  315/1000  loss: 47.082832\n",
            "epoch:  316/1000  loss: 47.036976\n",
            "epoch:  317/1000  loss: 46.991234\n",
            "epoch:  318/1000  loss: 46.945591\n",
            "epoch:  319/1000  loss: 46.900032\n",
            "epoch:  320/1000  loss: 46.854607\n",
            "epoch:  321/1000  loss: 46.809307\n",
            "epoch:  322/1000  loss: 46.764091\n",
            "epoch:  323/1000  loss: 46.718971\n",
            "epoch:  324/1000  loss: 46.673950\n",
            "epoch:  325/1000  loss: 46.629066\n",
            "epoch:  326/1000  loss: 46.584251\n",
            "epoch:  327/1000  loss: 46.539589\n",
            "epoch:  328/1000  loss: 46.494987\n",
            "epoch:  329/1000  loss: 46.450542\n",
            "epoch:  330/1000  loss: 46.406197\n",
            "epoch:  331/1000  loss: 46.361977\n",
            "epoch:  332/1000  loss: 46.317814\n",
            "epoch:  333/1000  loss: 46.273781\n",
            "epoch:  334/1000  loss: 46.229847\n",
            "epoch:  335/1000  loss: 46.186031\n",
            "epoch:  336/1000  loss: 46.142326\n",
            "epoch:  337/1000  loss: 46.098755\n",
            "epoch:  338/1000  loss: 46.055225\n",
            "epoch:  339/1000  loss: 46.011826\n",
            "epoch:  340/1000  loss: 45.968605\n",
            "epoch:  341/1000  loss: 45.925426\n",
            "epoch:  342/1000  loss: 45.882355\n",
            "epoch:  343/1000  loss: 45.839378\n",
            "epoch:  344/1000  loss: 45.796570\n",
            "epoch:  345/1000  loss: 45.753864\n",
            "epoch:  346/1000  loss: 45.711224\n",
            "epoch:  347/1000  loss: 45.668747\n",
            "epoch:  348/1000  loss: 45.626316\n",
            "epoch:  349/1000  loss: 45.584034\n",
            "epoch:  350/1000  loss: 45.541843\n",
            "epoch:  351/1000  loss: 45.499741\n",
            "epoch:  352/1000  loss: 45.457794\n",
            "epoch:  353/1000  loss: 45.415947\n",
            "epoch:  354/1000  loss: 45.374191\n",
            "epoch:  355/1000  loss: 45.332561\n",
            "epoch:  356/1000  loss: 45.291042\n",
            "epoch:  357/1000  loss: 45.249615\n",
            "epoch:  358/1000  loss: 45.208294\n",
            "epoch:  359/1000  loss: 45.167072\n",
            "epoch:  360/1000  loss: 45.126015\n",
            "epoch:  361/1000  loss: 45.085014\n",
            "epoch:  362/1000  loss: 45.044121\n",
            "epoch:  363/1000  loss: 45.003357\n",
            "epoch:  364/1000  loss: 44.962688\n",
            "epoch:  365/1000  loss: 44.922150\n",
            "epoch:  366/1000  loss: 44.881699\n",
            "epoch:  367/1000  loss: 44.841335\n",
            "epoch:  368/1000  loss: 44.801128\n",
            "epoch:  369/1000  loss: 44.760986\n",
            "epoch:  370/1000  loss: 44.720989\n",
            "epoch:  371/1000  loss: 44.681072\n",
            "epoch:  372/1000  loss: 44.641285\n",
            "epoch:  373/1000  loss: 44.601566\n",
            "epoch:  374/1000  loss: 44.561962\n",
            "epoch:  375/1000  loss: 44.522503\n",
            "epoch:  376/1000  loss: 44.483116\n",
            "epoch:  377/1000  loss: 44.443878\n",
            "epoch:  378/1000  loss: 44.404690\n",
            "epoch:  379/1000  loss: 44.365658\n",
            "epoch:  380/1000  loss: 44.326706\n",
            "epoch:  381/1000  loss: 44.287846\n",
            "epoch:  382/1000  loss: 44.249084\n",
            "epoch:  383/1000  loss: 44.210461\n",
            "epoch:  384/1000  loss: 44.171932\n",
            "epoch:  385/1000  loss: 44.133511\n",
            "epoch:  386/1000  loss: 44.095173\n",
            "epoch:  387/1000  loss: 44.056927\n",
            "epoch:  388/1000  loss: 44.018822\n",
            "epoch:  389/1000  loss: 43.980820\n",
            "epoch:  390/1000  loss: 43.942928\n",
            "epoch:  391/1000  loss: 43.905087\n",
            "epoch:  392/1000  loss: 43.867401\n",
            "epoch:  393/1000  loss: 43.829792\n",
            "epoch:  394/1000  loss: 43.792286\n",
            "epoch:  395/1000  loss: 43.754913\n",
            "epoch:  396/1000  loss: 43.717628\n",
            "epoch:  397/1000  loss: 43.680435\n",
            "epoch:  398/1000  loss: 43.643295\n",
            "epoch:  399/1000  loss: 43.606354\n",
            "epoch:  400/1000  loss: 43.569416\n",
            "epoch:  401/1000  loss: 43.532669\n",
            "epoch:  402/1000  loss: 43.495918\n",
            "epoch:  403/1000  loss: 43.459343\n",
            "epoch:  404/1000  loss: 43.422844\n",
            "epoch:  405/1000  loss: 43.386475\n",
            "epoch:  406/1000  loss: 43.350170\n",
            "epoch:  407/1000  loss: 43.313942\n",
            "epoch:  408/1000  loss: 43.277855\n",
            "epoch:  409/1000  loss: 43.241859\n",
            "epoch:  410/1000  loss: 43.205940\n",
            "epoch:  411/1000  loss: 43.170135\n",
            "epoch:  412/1000  loss: 43.134418\n",
            "epoch:  413/1000  loss: 43.098789\n",
            "epoch:  414/1000  loss: 43.063278\n",
            "epoch:  415/1000  loss: 43.027836\n",
            "epoch:  416/1000  loss: 42.992519\n",
            "epoch:  417/1000  loss: 42.957245\n",
            "epoch:  418/1000  loss: 42.922112\n",
            "epoch:  419/1000  loss: 42.887093\n",
            "epoch:  420/1000  loss: 42.852142\n",
            "epoch:  421/1000  loss: 42.817265\n",
            "epoch:  422/1000  loss: 42.782486\n",
            "epoch:  423/1000  loss: 42.747833\n",
            "epoch:  424/1000  loss: 42.713215\n",
            "epoch:  425/1000  loss: 42.678726\n",
            "epoch:  426/1000  loss: 42.644310\n",
            "epoch:  427/1000  loss: 42.610023\n",
            "epoch:  428/1000  loss: 42.575783\n",
            "epoch:  429/1000  loss: 42.541649\n",
            "epoch:  430/1000  loss: 42.507618\n",
            "epoch:  431/1000  loss: 42.473648\n",
            "epoch:  432/1000  loss: 42.439789\n",
            "epoch:  433/1000  loss: 42.406017\n",
            "epoch:  434/1000  loss: 42.372314\n",
            "epoch:  435/1000  loss: 42.338688\n",
            "epoch:  436/1000  loss: 42.305199\n",
            "epoch:  437/1000  loss: 42.271778\n",
            "epoch:  438/1000  loss: 42.238419\n",
            "epoch:  439/1000  loss: 42.205158\n",
            "epoch:  440/1000  loss: 42.171982\n",
            "epoch:  441/1000  loss: 42.138920\n",
            "epoch:  442/1000  loss: 42.105915\n",
            "epoch:  443/1000  loss: 42.073002\n",
            "epoch:  444/1000  loss: 42.040150\n",
            "epoch:  445/1000  loss: 42.007393\n",
            "epoch:  446/1000  loss: 41.974735\n",
            "epoch:  447/1000  loss: 41.942146\n",
            "epoch:  448/1000  loss: 41.909615\n",
            "epoch:  449/1000  loss: 41.877220\n",
            "epoch:  450/1000  loss: 41.844883\n",
            "epoch:  451/1000  loss: 41.812603\n",
            "epoch:  452/1000  loss: 41.780422\n",
            "epoch:  453/1000  loss: 41.748329\n",
            "epoch:  454/1000  loss: 41.716297\n",
            "epoch:  455/1000  loss: 41.684357\n",
            "epoch:  456/1000  loss: 41.652493\n",
            "epoch:  457/1000  loss: 41.620712\n",
            "epoch:  458/1000  loss: 41.589012\n",
            "epoch:  459/1000  loss: 41.557343\n",
            "epoch:  460/1000  loss: 41.525803\n",
            "epoch:  461/1000  loss: 41.494347\n",
            "epoch:  462/1000  loss: 41.462921\n",
            "epoch:  463/1000  loss: 41.431618\n",
            "epoch:  464/1000  loss: 41.400352\n",
            "epoch:  465/1000  loss: 41.369175\n",
            "epoch:  466/1000  loss: 41.338058\n",
            "epoch:  467/1000  loss: 41.307037\n",
            "epoch:  468/1000  loss: 41.276085\n",
            "epoch:  469/1000  loss: 41.245197\n",
            "epoch:  470/1000  loss: 41.214390\n",
            "epoch:  471/1000  loss: 41.183632\n",
            "epoch:  472/1000  loss: 41.152958\n",
            "epoch:  473/1000  loss: 41.122372\n",
            "epoch:  474/1000  loss: 41.091846\n",
            "epoch:  475/1000  loss: 41.061382\n",
            "epoch:  476/1000  loss: 41.031029\n",
            "epoch:  477/1000  loss: 41.000675\n",
            "epoch:  478/1000  loss: 40.970440\n",
            "epoch:  479/1000  loss: 40.940273\n",
            "epoch:  480/1000  loss: 40.910141\n",
            "epoch:  481/1000  loss: 40.880089\n",
            "epoch:  482/1000  loss: 40.850151\n",
            "epoch:  483/1000  loss: 40.820213\n",
            "epoch:  484/1000  loss: 40.790379\n",
            "epoch:  485/1000  loss: 40.760635\n",
            "epoch:  486/1000  loss: 40.730881\n",
            "epoch:  487/1000  loss: 40.701237\n",
            "epoch:  488/1000  loss: 40.671669\n",
            "epoch:  489/1000  loss: 40.642147\n",
            "epoch:  490/1000  loss: 40.612679\n",
            "epoch:  491/1000  loss: 40.583298\n",
            "epoch:  492/1000  loss: 40.553978\n",
            "epoch:  493/1000  loss: 40.524727\n",
            "epoch:  494/1000  loss: 40.495525\n",
            "epoch:  495/1000  loss: 40.466366\n",
            "epoch:  496/1000  loss: 40.437313\n",
            "epoch:  497/1000  loss: 40.408272\n",
            "epoch:  498/1000  loss: 40.379360\n",
            "epoch:  499/1000  loss: 40.350449\n",
            "epoch:  500/1000  loss: 40.321629\n",
            "epoch:  501/1000  loss: 40.292847\n",
            "epoch:  502/1000  loss: 40.264107\n",
            "epoch:  503/1000  loss: 40.235477\n",
            "epoch:  504/1000  loss: 40.206856\n",
            "epoch:  505/1000  loss: 40.178337\n",
            "epoch:  506/1000  loss: 40.149834\n",
            "epoch:  507/1000  loss: 40.121403\n",
            "epoch:  508/1000  loss: 40.093052\n",
            "epoch:  509/1000  loss: 40.064758\n",
            "epoch:  510/1000  loss: 40.036491\n",
            "epoch:  511/1000  loss: 40.008312\n",
            "epoch:  512/1000  loss: 39.980137\n",
            "epoch:  513/1000  loss: 39.952053\n",
            "epoch:  514/1000  loss: 39.924023\n",
            "epoch:  515/1000  loss: 39.896046\n",
            "epoch:  516/1000  loss: 39.868107\n",
            "epoch:  517/1000  loss: 39.840229\n",
            "epoch:  518/1000  loss: 39.812431\n",
            "epoch:  519/1000  loss: 39.784664\n",
            "epoch:  520/1000  loss: 39.756954\n",
            "epoch:  521/1000  loss: 39.729309\n",
            "epoch:  522/1000  loss: 39.701698\n",
            "epoch:  523/1000  loss: 39.674152\n",
            "epoch:  524/1000  loss: 39.646626\n",
            "epoch:  525/1000  loss: 39.619190\n",
            "epoch:  526/1000  loss: 39.591770\n",
            "epoch:  527/1000  loss: 39.564430\n",
            "epoch:  528/1000  loss: 39.537125\n",
            "epoch:  529/1000  loss: 39.509880\n",
            "epoch:  530/1000  loss: 39.482689\n",
            "epoch:  531/1000  loss: 39.455536\n",
            "epoch:  532/1000  loss: 39.428425\n",
            "epoch:  533/1000  loss: 39.401344\n",
            "epoch:  534/1000  loss: 39.374355\n",
            "epoch:  535/1000  loss: 39.347389\n",
            "epoch:  536/1000  loss: 39.320492\n",
            "epoch:  537/1000  loss: 39.293640\n",
            "epoch:  538/1000  loss: 39.266804\n",
            "epoch:  539/1000  loss: 39.240040\n",
            "epoch:  540/1000  loss: 39.213303\n",
            "epoch:  541/1000  loss: 39.186626\n",
            "epoch:  542/1000  loss: 39.159977\n",
            "epoch:  543/1000  loss: 39.133396\n",
            "epoch:  544/1000  loss: 39.106865\n",
            "epoch:  545/1000  loss: 39.080357\n",
            "epoch:  546/1000  loss: 39.053902\n",
            "epoch:  547/1000  loss: 39.027519\n",
            "epoch:  548/1000  loss: 39.001133\n",
            "epoch:  549/1000  loss: 38.974808\n",
            "epoch:  550/1000  loss: 38.948555\n",
            "epoch:  551/1000  loss: 38.922333\n",
            "epoch:  552/1000  loss: 38.896141\n",
            "epoch:  553/1000  loss: 38.869999\n",
            "epoch:  554/1000  loss: 38.843861\n",
            "epoch:  555/1000  loss: 38.817841\n",
            "epoch:  556/1000  loss: 38.791794\n",
            "epoch:  557/1000  loss: 38.765820\n",
            "epoch:  558/1000  loss: 38.739891\n",
            "epoch:  559/1000  loss: 38.713970\n",
            "epoch:  560/1000  loss: 38.688129\n",
            "epoch:  561/1000  loss: 38.662323\n",
            "epoch:  562/1000  loss: 38.636570\n",
            "epoch:  563/1000  loss: 38.610809\n",
            "epoch:  564/1000  loss: 38.585106\n",
            "epoch:  565/1000  loss: 38.559483\n",
            "epoch:  566/1000  loss: 38.533848\n",
            "epoch:  567/1000  loss: 38.508266\n",
            "epoch:  568/1000  loss: 38.482758\n",
            "epoch:  569/1000  loss: 38.457237\n",
            "epoch:  570/1000  loss: 38.431789\n",
            "epoch:  571/1000  loss: 38.406376\n",
            "epoch:  572/1000  loss: 38.380974\n",
            "epoch:  573/1000  loss: 38.355644\n",
            "epoch:  574/1000  loss: 38.330326\n",
            "epoch:  575/1000  loss: 38.305077\n",
            "epoch:  576/1000  loss: 38.279827\n",
            "epoch:  577/1000  loss: 38.254623\n",
            "epoch:  578/1000  loss: 38.229496\n",
            "epoch:  579/1000  loss: 38.204361\n",
            "epoch:  580/1000  loss: 38.179287\n",
            "epoch:  581/1000  loss: 38.154247\n",
            "epoch:  582/1000  loss: 38.129238\n",
            "epoch:  583/1000  loss: 38.104271\n",
            "epoch:  584/1000  loss: 38.079315\n",
            "epoch:  585/1000  loss: 38.054428\n",
            "epoch:  586/1000  loss: 38.029545\n",
            "epoch:  587/1000  loss: 38.004730\n",
            "epoch:  588/1000  loss: 37.979935\n",
            "epoch:  589/1000  loss: 37.955185\n",
            "epoch:  590/1000  loss: 37.930450\n",
            "epoch:  591/1000  loss: 37.905720\n",
            "epoch:  592/1000  loss: 37.881058\n",
            "epoch:  593/1000  loss: 37.856468\n",
            "epoch:  594/1000  loss: 37.831875\n",
            "epoch:  595/1000  loss: 37.807301\n",
            "epoch:  596/1000  loss: 37.782791\n",
            "epoch:  597/1000  loss: 37.758297\n",
            "epoch:  598/1000  loss: 37.733864\n",
            "epoch:  599/1000  loss: 37.709415\n",
            "epoch:  600/1000  loss: 37.685043\n",
            "epoch:  601/1000  loss: 37.660671\n",
            "epoch:  602/1000  loss: 37.636349\n",
            "epoch:  603/1000  loss: 37.612038\n",
            "epoch:  604/1000  loss: 37.587799\n",
            "epoch:  605/1000  loss: 37.563572\n",
            "epoch:  606/1000  loss: 37.539364\n",
            "epoch:  607/1000  loss: 37.515224\n",
            "epoch:  608/1000  loss: 37.491062\n",
            "epoch:  609/1000  loss: 37.466957\n",
            "epoch:  610/1000  loss: 37.442909\n",
            "epoch:  611/1000  loss: 37.418865\n",
            "epoch:  612/1000  loss: 37.394863\n",
            "epoch:  613/1000  loss: 37.370884\n",
            "epoch:  614/1000  loss: 37.346939\n",
            "epoch:  615/1000  loss: 37.323055\n",
            "epoch:  616/1000  loss: 37.299149\n",
            "epoch:  617/1000  loss: 37.275288\n",
            "epoch:  618/1000  loss: 37.251461\n",
            "epoch:  619/1000  loss: 37.227688\n",
            "epoch:  620/1000  loss: 37.203918\n",
            "epoch:  621/1000  loss: 37.180180\n",
            "epoch:  622/1000  loss: 37.156483\n",
            "epoch:  623/1000  loss: 37.132797\n",
            "epoch:  624/1000  loss: 37.109138\n",
            "epoch:  625/1000  loss: 37.085533\n",
            "epoch:  626/1000  loss: 37.061943\n",
            "epoch:  627/1000  loss: 37.038391\n",
            "epoch:  628/1000  loss: 37.014862\n",
            "epoch:  629/1000  loss: 36.991375\n",
            "epoch:  630/1000  loss: 36.967876\n",
            "epoch:  631/1000  loss: 36.944427\n",
            "epoch:  632/1000  loss: 36.921024\n",
            "epoch:  633/1000  loss: 36.897648\n",
            "epoch:  634/1000  loss: 36.874294\n",
            "epoch:  635/1000  loss: 36.850979\n",
            "epoch:  636/1000  loss: 36.827675\n",
            "epoch:  637/1000  loss: 36.804363\n",
            "epoch:  638/1000  loss: 36.781136\n",
            "epoch:  639/1000  loss: 36.757908\n",
            "epoch:  640/1000  loss: 36.734741\n",
            "epoch:  641/1000  loss: 36.711567\n",
            "epoch:  642/1000  loss: 36.688427\n",
            "epoch:  643/1000  loss: 36.665314\n",
            "epoch:  644/1000  loss: 36.642239\n",
            "epoch:  645/1000  loss: 36.619190\n",
            "epoch:  646/1000  loss: 36.596123\n",
            "epoch:  647/1000  loss: 36.573139\n",
            "epoch:  648/1000  loss: 36.550144\n",
            "epoch:  649/1000  loss: 36.527222\n",
            "epoch:  650/1000  loss: 36.504299\n",
            "epoch:  651/1000  loss: 36.481365\n",
            "epoch:  652/1000  loss: 36.458538\n",
            "epoch:  653/1000  loss: 36.435650\n",
            "epoch:  654/1000  loss: 36.412846\n",
            "epoch:  655/1000  loss: 36.390068\n",
            "epoch:  656/1000  loss: 36.367279\n",
            "epoch:  657/1000  loss: 36.344559\n",
            "epoch:  658/1000  loss: 36.321835\n",
            "epoch:  659/1000  loss: 36.299122\n",
            "epoch:  660/1000  loss: 36.276466\n",
            "epoch:  661/1000  loss: 36.253811\n",
            "epoch:  662/1000  loss: 36.231216\n",
            "epoch:  663/1000  loss: 36.208618\n",
            "epoch:  664/1000  loss: 36.186058\n",
            "epoch:  665/1000  loss: 36.163517\n",
            "epoch:  666/1000  loss: 36.140991\n",
            "epoch:  667/1000  loss: 36.118496\n",
            "epoch:  668/1000  loss: 36.096035\n",
            "epoch:  669/1000  loss: 36.073616\n",
            "epoch:  670/1000  loss: 36.051201\n",
            "epoch:  671/1000  loss: 36.028767\n",
            "epoch:  672/1000  loss: 36.006405\n",
            "epoch:  673/1000  loss: 35.984062\n",
            "epoch:  674/1000  loss: 35.961727\n",
            "epoch:  675/1000  loss: 35.939430\n",
            "epoch:  676/1000  loss: 35.917168\n",
            "epoch:  677/1000  loss: 35.894920\n",
            "epoch:  678/1000  loss: 35.872681\n",
            "epoch:  679/1000  loss: 35.850464\n",
            "epoch:  680/1000  loss: 35.828285\n",
            "epoch:  681/1000  loss: 35.806133\n",
            "epoch:  682/1000  loss: 35.784004\n",
            "epoch:  683/1000  loss: 35.761871\n",
            "epoch:  684/1000  loss: 35.739769\n",
            "epoch:  685/1000  loss: 35.717705\n",
            "epoch:  686/1000  loss: 35.695671\n",
            "epoch:  687/1000  loss: 35.673653\n",
            "epoch:  688/1000  loss: 35.651653\n",
            "epoch:  689/1000  loss: 35.629673\n",
            "epoch:  690/1000  loss: 35.607716\n",
            "epoch:  691/1000  loss: 35.585789\n",
            "epoch:  692/1000  loss: 35.563877\n",
            "epoch:  693/1000  loss: 35.541962\n",
            "epoch:  694/1000  loss: 35.520073\n",
            "epoch:  695/1000  loss: 35.498241\n",
            "epoch:  696/1000  loss: 35.476463\n",
            "epoch:  697/1000  loss: 35.454639\n",
            "epoch:  698/1000  loss: 35.432831\n",
            "epoch:  699/1000  loss: 35.411118\n",
            "epoch:  700/1000  loss: 35.389351\n",
            "epoch:  701/1000  loss: 35.367649\n",
            "epoch:  702/1000  loss: 35.345936\n",
            "epoch:  703/1000  loss: 35.324291\n",
            "epoch:  704/1000  loss: 35.302608\n",
            "epoch:  705/1000  loss: 35.280983\n",
            "epoch:  706/1000  loss: 35.259354\n",
            "epoch:  707/1000  loss: 35.237801\n",
            "epoch:  708/1000  loss: 35.216228\n",
            "epoch:  709/1000  loss: 35.194656\n",
            "epoch:  710/1000  loss: 35.173138\n",
            "epoch:  711/1000  loss: 35.151627\n",
            "epoch:  712/1000  loss: 35.130165\n",
            "epoch:  713/1000  loss: 35.108662\n",
            "epoch:  714/1000  loss: 35.087246\n",
            "epoch:  715/1000  loss: 35.065807\n",
            "epoch:  716/1000  loss: 35.044399\n",
            "epoch:  717/1000  loss: 35.023029\n",
            "epoch:  718/1000  loss: 35.001671\n",
            "epoch:  719/1000  loss: 34.980301\n",
            "epoch:  720/1000  loss: 34.958950\n",
            "epoch:  721/1000  loss: 34.937660\n",
            "epoch:  722/1000  loss: 34.916367\n",
            "epoch:  723/1000  loss: 34.895096\n",
            "epoch:  724/1000  loss: 34.873844\n",
            "epoch:  725/1000  loss: 34.852612\n",
            "epoch:  726/1000  loss: 34.831409\n",
            "epoch:  727/1000  loss: 34.810177\n",
            "epoch:  728/1000  loss: 34.789009\n",
            "epoch:  729/1000  loss: 34.767864\n",
            "epoch:  730/1000  loss: 34.746716\n",
            "epoch:  731/1000  loss: 34.725620\n",
            "epoch:  732/1000  loss: 34.704502\n",
            "epoch:  733/1000  loss: 34.683445\n",
            "epoch:  734/1000  loss: 34.662354\n",
            "epoch:  735/1000  loss: 34.641315\n",
            "epoch:  736/1000  loss: 34.620277\n",
            "epoch:  737/1000  loss: 34.599277\n",
            "epoch:  738/1000  loss: 34.578300\n",
            "epoch:  739/1000  loss: 34.557316\n",
            "epoch:  740/1000  loss: 34.536396\n",
            "epoch:  741/1000  loss: 34.515419\n",
            "epoch:  742/1000  loss: 34.494488\n",
            "epoch:  743/1000  loss: 34.473595\n",
            "epoch:  744/1000  loss: 34.452744\n",
            "epoch:  745/1000  loss: 34.431835\n",
            "epoch:  746/1000  loss: 34.411022\n",
            "epoch:  747/1000  loss: 34.390160\n",
            "epoch:  748/1000  loss: 34.369343\n",
            "epoch:  749/1000  loss: 34.348541\n",
            "epoch:  750/1000  loss: 34.327797\n",
            "epoch:  751/1000  loss: 34.306980\n",
            "epoch:  752/1000  loss: 34.286255\n",
            "epoch:  753/1000  loss: 34.265514\n",
            "epoch:  754/1000  loss: 34.244831\n",
            "epoch:  755/1000  loss: 34.224102\n",
            "epoch:  756/1000  loss: 34.203415\n",
            "epoch:  757/1000  loss: 34.182758\n",
            "epoch:  758/1000  loss: 34.162117\n",
            "epoch:  759/1000  loss: 34.141476\n",
            "epoch:  760/1000  loss: 34.120872\n",
            "epoch:  761/1000  loss: 34.100269\n",
            "epoch:  762/1000  loss: 34.079674\n",
            "epoch:  763/1000  loss: 34.059097\n",
            "epoch:  764/1000  loss: 34.038548\n",
            "epoch:  765/1000  loss: 34.018024\n",
            "epoch:  766/1000  loss: 33.997467\n",
            "epoch:  767/1000  loss: 33.976963\n",
            "epoch:  768/1000  loss: 33.956482\n",
            "epoch:  769/1000  loss: 33.936028\n",
            "epoch:  770/1000  loss: 33.915554\n",
            "epoch:  771/1000  loss: 33.895115\n",
            "epoch:  772/1000  loss: 33.874664\n",
            "epoch:  773/1000  loss: 33.854244\n",
            "epoch:  774/1000  loss: 33.833851\n",
            "epoch:  775/1000  loss: 33.813469\n",
            "epoch:  776/1000  loss: 33.793114\n",
            "epoch:  777/1000  loss: 33.772732\n",
            "epoch:  778/1000  loss: 33.752411\n",
            "epoch:  779/1000  loss: 33.732071\n",
            "epoch:  780/1000  loss: 33.711739\n",
            "epoch:  781/1000  loss: 33.691437\n",
            "epoch:  782/1000  loss: 33.671177\n",
            "epoch:  783/1000  loss: 33.650902\n",
            "epoch:  784/1000  loss: 33.630642\n",
            "epoch:  785/1000  loss: 33.610390\n",
            "epoch:  786/1000  loss: 33.590160\n",
            "epoch:  787/1000  loss: 33.569946\n",
            "epoch:  788/1000  loss: 33.549763\n",
            "epoch:  789/1000  loss: 33.529549\n",
            "epoch:  790/1000  loss: 33.509392\n",
            "epoch:  791/1000  loss: 33.489243\n",
            "epoch:  792/1000  loss: 33.469093\n",
            "epoch:  793/1000  loss: 33.448936\n",
            "epoch:  794/1000  loss: 33.428829\n",
            "epoch:  795/1000  loss: 33.408726\n",
            "epoch:  796/1000  loss: 33.388634\n",
            "epoch:  797/1000  loss: 33.368561\n",
            "epoch:  798/1000  loss: 33.348484\n",
            "epoch:  799/1000  loss: 33.328438\n",
            "epoch:  800/1000  loss: 33.308376\n",
            "epoch:  801/1000  loss: 33.288345\n",
            "epoch:  802/1000  loss: 33.268341\n",
            "epoch:  803/1000  loss: 33.248306\n",
            "epoch:  804/1000  loss: 33.228344\n",
            "epoch:  805/1000  loss: 33.208370\n",
            "epoch:  806/1000  loss: 33.188400\n",
            "epoch:  807/1000  loss: 33.168453\n",
            "epoch:  808/1000  loss: 33.148487\n",
            "epoch:  809/1000  loss: 33.128571\n",
            "epoch:  810/1000  loss: 33.108646\n",
            "epoch:  811/1000  loss: 33.088718\n",
            "epoch:  812/1000  loss: 33.068844\n",
            "epoch:  813/1000  loss: 33.048962\n",
            "epoch:  814/1000  loss: 33.029072\n",
            "epoch:  815/1000  loss: 33.009228\n",
            "epoch:  816/1000  loss: 32.989399\n",
            "epoch:  817/1000  loss: 32.969559\n",
            "epoch:  818/1000  loss: 32.949711\n",
            "epoch:  819/1000  loss: 32.929909\n",
            "epoch:  820/1000  loss: 32.910103\n",
            "epoch:  821/1000  loss: 32.890324\n",
            "epoch:  822/1000  loss: 32.870541\n",
            "epoch:  823/1000  loss: 32.850784\n",
            "epoch:  824/1000  loss: 32.831005\n",
            "epoch:  825/1000  loss: 32.811256\n",
            "epoch:  826/1000  loss: 32.791534\n",
            "epoch:  827/1000  loss: 32.771809\n",
            "epoch:  828/1000  loss: 32.752094\n",
            "epoch:  829/1000  loss: 32.732395\n",
            "epoch:  830/1000  loss: 32.712696\n",
            "epoch:  831/1000  loss: 32.693020\n",
            "epoch:  832/1000  loss: 32.673325\n",
            "epoch:  833/1000  loss: 32.653687\n",
            "epoch:  834/1000  loss: 32.634010\n",
            "epoch:  835/1000  loss: 32.614388\n",
            "epoch:  836/1000  loss: 32.594738\n",
            "epoch:  837/1000  loss: 32.575138\n",
            "epoch:  838/1000  loss: 32.555515\n",
            "epoch:  839/1000  loss: 32.535923\n",
            "epoch:  840/1000  loss: 32.516315\n",
            "epoch:  841/1000  loss: 32.496750\n",
            "epoch:  842/1000  loss: 32.477184\n",
            "epoch:  843/1000  loss: 32.457607\n",
            "epoch:  844/1000  loss: 32.438053\n",
            "epoch:  845/1000  loss: 32.418545\n",
            "epoch:  846/1000  loss: 32.398991\n",
            "epoch:  847/1000  loss: 32.379459\n",
            "epoch:  848/1000  loss: 32.359947\n",
            "epoch:  849/1000  loss: 32.340462\n",
            "epoch:  850/1000  loss: 32.320934\n",
            "epoch:  851/1000  loss: 32.301476\n",
            "epoch:  852/1000  loss: 32.282005\n",
            "epoch:  853/1000  loss: 32.262550\n",
            "epoch:  854/1000  loss: 32.243065\n",
            "epoch:  855/1000  loss: 32.223637\n",
            "epoch:  856/1000  loss: 32.204185\n",
            "epoch:  857/1000  loss: 32.184750\n",
            "epoch:  858/1000  loss: 32.165333\n",
            "epoch:  859/1000  loss: 32.145908\n",
            "epoch:  860/1000  loss: 32.126534\n",
            "epoch:  861/1000  loss: 32.107136\n",
            "epoch:  862/1000  loss: 32.087730\n",
            "epoch:  863/1000  loss: 32.068371\n",
            "epoch:  864/1000  loss: 32.049015\n",
            "epoch:  865/1000  loss: 32.029621\n",
            "epoch:  866/1000  loss: 32.010292\n",
            "epoch:  867/1000  loss: 31.990948\n",
            "epoch:  868/1000  loss: 31.971621\n",
            "epoch:  869/1000  loss: 31.952295\n",
            "epoch:  870/1000  loss: 31.932987\n",
            "epoch:  871/1000  loss: 31.913649\n",
            "epoch:  872/1000  loss: 31.894352\n",
            "epoch:  873/1000  loss: 31.875093\n",
            "epoch:  874/1000  loss: 31.855778\n",
            "epoch:  875/1000  loss: 31.836483\n",
            "epoch:  876/1000  loss: 31.817232\n",
            "epoch:  877/1000  loss: 31.797991\n",
            "epoch:  878/1000  loss: 31.778709\n",
            "epoch:  879/1000  loss: 31.759481\n",
            "epoch:  880/1000  loss: 31.740215\n",
            "epoch:  881/1000  loss: 31.721001\n",
            "epoch:  882/1000  loss: 31.701792\n",
            "epoch:  883/1000  loss: 31.682547\n",
            "epoch:  884/1000  loss: 31.663376\n",
            "epoch:  885/1000  loss: 31.644201\n",
            "epoch:  886/1000  loss: 31.625006\n",
            "epoch:  887/1000  loss: 31.605814\n",
            "epoch:  888/1000  loss: 31.586651\n",
            "epoch:  889/1000  loss: 31.567474\n",
            "epoch:  890/1000  loss: 31.548321\n",
            "epoch:  891/1000  loss: 31.529152\n",
            "epoch:  892/1000  loss: 31.510010\n",
            "epoch:  893/1000  loss: 31.490866\n",
            "epoch:  894/1000  loss: 31.471771\n",
            "epoch:  895/1000  loss: 31.452635\n",
            "epoch:  896/1000  loss: 31.433529\n",
            "epoch:  897/1000  loss: 31.414391\n",
            "epoch:  898/1000  loss: 31.395317\n",
            "epoch:  899/1000  loss: 31.376219\n",
            "epoch:  900/1000  loss: 31.357134\n",
            "epoch:  901/1000  loss: 31.338041\n",
            "epoch:  902/1000  loss: 31.318995\n",
            "epoch:  903/1000  loss: 31.299929\n",
            "epoch:  904/1000  loss: 31.280849\n",
            "epoch:  905/1000  loss: 31.261837\n",
            "epoch:  906/1000  loss: 31.242794\n",
            "epoch:  907/1000  loss: 31.223770\n",
            "epoch:  908/1000  loss: 31.204716\n",
            "epoch:  909/1000  loss: 31.185707\n",
            "epoch:  910/1000  loss: 31.166704\n",
            "epoch:  911/1000  loss: 31.147692\n",
            "epoch:  912/1000  loss: 31.128696\n",
            "epoch:  913/1000  loss: 31.109718\n",
            "epoch:  914/1000  loss: 31.090715\n",
            "epoch:  915/1000  loss: 31.071739\n",
            "epoch:  916/1000  loss: 31.052750\n",
            "epoch:  917/1000  loss: 31.033821\n",
            "epoch:  918/1000  loss: 31.014868\n",
            "epoch:  919/1000  loss: 30.995890\n",
            "epoch:  920/1000  loss: 30.976959\n",
            "epoch:  921/1000  loss: 30.958015\n",
            "epoch:  922/1000  loss: 30.939096\n",
            "epoch:  923/1000  loss: 30.920200\n",
            "epoch:  924/1000  loss: 30.901281\n",
            "epoch:  925/1000  loss: 30.882364\n",
            "epoch:  926/1000  loss: 30.863459\n",
            "epoch:  927/1000  loss: 30.844576\n",
            "epoch:  928/1000  loss: 30.825686\n",
            "epoch:  929/1000  loss: 30.806801\n",
            "epoch:  930/1000  loss: 30.787933\n",
            "epoch:  931/1000  loss: 30.769062\n",
            "epoch:  932/1000  loss: 30.750242\n",
            "epoch:  933/1000  loss: 30.731348\n",
            "epoch:  934/1000  loss: 30.712532\n",
            "epoch:  935/1000  loss: 30.693687\n",
            "epoch:  936/1000  loss: 30.674875\n",
            "epoch:  937/1000  loss: 30.656019\n",
            "epoch:  938/1000  loss: 30.637207\n",
            "epoch:  939/1000  loss: 30.618408\n",
            "epoch:  940/1000  loss: 30.599617\n",
            "epoch:  941/1000  loss: 30.580843\n",
            "epoch:  942/1000  loss: 30.562031\n",
            "epoch:  943/1000  loss: 30.543228\n",
            "epoch:  944/1000  loss: 30.524479\n",
            "epoch:  945/1000  loss: 30.505693\n",
            "epoch:  946/1000  loss: 30.486963\n",
            "epoch:  947/1000  loss: 30.468229\n",
            "epoch:  948/1000  loss: 30.449444\n",
            "epoch:  949/1000  loss: 30.430717\n",
            "epoch:  950/1000  loss: 30.411980\n",
            "epoch:  951/1000  loss: 30.393263\n",
            "epoch:  952/1000  loss: 30.374546\n",
            "epoch:  953/1000  loss: 30.355856\n",
            "epoch:  954/1000  loss: 30.337137\n",
            "epoch:  955/1000  loss: 30.318447\n",
            "epoch:  956/1000  loss: 30.299757\n",
            "epoch:  957/1000  loss: 30.281080\n",
            "epoch:  958/1000  loss: 30.262386\n",
            "epoch:  959/1000  loss: 30.243753\n",
            "epoch:  960/1000  loss: 30.225092\n",
            "epoch:  961/1000  loss: 30.206451\n",
            "epoch:  962/1000  loss: 30.187790\n",
            "epoch:  963/1000  loss: 30.169163\n",
            "epoch:  964/1000  loss: 30.150520\n",
            "epoch:  965/1000  loss: 30.131908\n",
            "epoch:  966/1000  loss: 30.113306\n",
            "epoch:  967/1000  loss: 30.094673\n",
            "epoch:  968/1000  loss: 30.076101\n",
            "epoch:  969/1000  loss: 30.057526\n",
            "epoch:  970/1000  loss: 30.038925\n",
            "epoch:  971/1000  loss: 30.020350\n",
            "epoch:  972/1000  loss: 30.001789\n",
            "epoch:  973/1000  loss: 29.983238\n",
            "epoch:  974/1000  loss: 29.964680\n",
            "epoch:  975/1000  loss: 29.946136\n",
            "epoch:  976/1000  loss: 29.927601\n",
            "epoch:  977/1000  loss: 29.909094\n",
            "epoch:  978/1000  loss: 29.890574\n",
            "epoch:  979/1000  loss: 29.872068\n",
            "epoch:  980/1000  loss: 29.853527\n",
            "epoch:  981/1000  loss: 29.835062\n",
            "epoch:  982/1000  loss: 29.816591\n",
            "epoch:  983/1000  loss: 29.798090\n",
            "epoch:  984/1000  loss: 29.779638\n",
            "epoch:  985/1000  loss: 29.761179\n",
            "epoch:  986/1000  loss: 29.742716\n",
            "epoch:  987/1000  loss: 29.724266\n",
            "epoch:  988/1000  loss: 29.705826\n",
            "epoch:  989/1000  loss: 29.687403\n",
            "epoch:  990/1000  loss: 29.668970\n",
            "epoch:  991/1000  loss: 29.650562\n",
            "epoch:  992/1000  loss: 29.632177\n",
            "epoch:  993/1000  loss: 29.613768\n",
            "epoch:  994/1000  loss: 29.595388\n",
            "epoch:  995/1000  loss: 29.577003\n",
            "epoch:  996/1000  loss: 29.558645\n",
            "epoch:  997/1000  loss: 29.540289\n",
            "epoch:  998/1000  loss: 29.521959\n",
            "epoch:  999/1000  loss: 29.503609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 테스트\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "with torch.no_grad():\n",
        "  prediction = model(X_valid)\n",
        "  mse = mean_squared_error(y_valid, prediction)\n",
        "  r2 = r2_score(y_valid, prediction)\n",
        "\n",
        "mse, r2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdyXMfsH922V",
        "outputId": "06b892a0-347f-4150-9a05-53a4e48af4a0"
      },
      "execution_count": 373,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32.51355, 0.5812235194320388)"
            ]
          },
          "metadata": {},
          "execution_count": 373
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 드롭아웃의 추가\n",
        "\n",
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Linear(13, 32),\n",
        "        nn.Dropout(0.2)    \n",
        "    )\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Linear(32, 16),\n",
        "        nn.Dropout(0.2)\n",
        "    )\n",
        "    self.layer3 = nn.Sequential(\n",
        "        nn.Linear(16, 1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.layer3(x)\n",
        "    return x\n",
        "\n",
        "  def weight_initialization(self):\n",
        "    self.layer1[0].weight.data = nn.init.kaiming_uniform_(self.layer1[0].weight.data)\n",
        "    self.layer2[0].weight.data = nn.init.kaiming_uniform_(self.layer2[0].weight.data)"
      ],
      "metadata": {
        "id": "ApdqcaB5ALl4"
      },
      "execution_count": 375,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model()\n",
        "model.weight_initialization()\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DwL_01zAxtF",
        "outputId": "4c036120-54fa-4f62-ebfd-d7241be31089"
      },
      "execution_count": 376,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (layer1): Sequential(\n",
              "    (0): Linear(in_features=13, out_features=32, bias=True)\n",
              "    (1): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Linear(in_features=32, out_features=16, bias=True)\n",
              "    (1): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Linear(in_features=16, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 376
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 조기종료의 추가\n",
        "\n",
        "class EarlyStopping:\n",
        "  def __init__(self, patience=5):\n",
        "    self.loss = np.inf\n",
        "    self.patience = 0\n",
        "    self.patience_limit = patience\n",
        "        \n",
        "  def step(self, loss):\n",
        "    if self.loss > loss:\n",
        "      self.loss = loss\n",
        "      self.patience = 0\n",
        "    else:\n",
        "      self.patience += 1\n",
        "  \n",
        "  def is_stop(self):\n",
        "    return self.patience >= self.patience_limit"
      ],
      "metadata": {
        "id": "UGJnLV30_0Lu"
      },
      "execution_count": 377,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(patience=15)"
      ],
      "metadata": {
        "id": "rNFrbtIQ_5ic"
      },
      "execution_count": 378,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 규제항 추가\n",
        "\n",
        "epochs=1000\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-5)"
      ],
      "metadata": {
        "id": "GMGRrlRKAMmZ"
      },
      "execution_count": 379,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  prediction = model(X_train)\n",
        "  loss = F.mse_loss(prediction, y_train)\n",
        "  early_stop.step(loss.item())\n",
        "  if early_stop.is_stop():\n",
        "    break\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  print(f'epoch: {epoch:4d}/{epochs}  loss: {loss.item():.6f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvZkR0tD_57s",
        "outputId": "5b0b2b5c-4e52-4324-8b6f-fe483ff409b7"
      },
      "execution_count": 380,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:    0/1000  loss: 47759.003906\n",
            "epoch:    1/1000  loss: 16481.246094\n",
            "epoch:    2/1000  loss: 15606.392578\n",
            "epoch:    3/1000  loss: 22969.232422\n",
            "epoch:    4/1000  loss: 17331.005859\n",
            "epoch:    5/1000  loss: 11777.899414\n",
            "epoch:    6/1000  loss: 8292.807617\n",
            "epoch:    7/1000  loss: 6207.759766\n",
            "epoch:    8/1000  loss: 6724.564453\n",
            "epoch:    9/1000  loss: 8174.574707\n",
            "epoch:   10/1000  loss: 8274.653320\n",
            "epoch:   11/1000  loss: 6756.573730\n",
            "epoch:   12/1000  loss: 5354.865723\n",
            "epoch:   13/1000  loss: 3782.728271\n",
            "epoch:   14/1000  loss: 2602.690918\n",
            "epoch:   15/1000  loss: 2126.123779\n",
            "epoch:   16/1000  loss: 1669.335205\n",
            "epoch:   17/1000  loss: 1548.643188\n",
            "epoch:   18/1000  loss: 1776.994873\n",
            "epoch:   19/1000  loss: 1763.064697\n",
            "epoch:   20/1000  loss: 1616.739868\n",
            "epoch:   21/1000  loss: 1722.711914\n",
            "epoch:   22/1000  loss: 1835.878906\n",
            "epoch:   23/1000  loss: 1649.150391\n",
            "epoch:   24/1000  loss: 1440.202637\n",
            "epoch:   25/1000  loss: 1276.914185\n",
            "epoch:   26/1000  loss: 1163.411255\n",
            "epoch:   27/1000  loss: 995.238220\n",
            "epoch:   28/1000  loss: 937.471680\n",
            "epoch:   29/1000  loss: 592.788696\n",
            "epoch:   30/1000  loss: 685.175232\n",
            "epoch:   31/1000  loss: 613.943115\n",
            "epoch:   32/1000  loss: 560.015381\n",
            "epoch:   33/1000  loss: 530.411621\n",
            "epoch:   34/1000  loss: 497.647400\n",
            "epoch:   35/1000  loss: 476.777313\n",
            "epoch:   36/1000  loss: 466.713440\n",
            "epoch:   37/1000  loss: 503.188873\n",
            "epoch:   38/1000  loss: 482.001373\n",
            "epoch:   39/1000  loss: 445.059448\n",
            "epoch:   40/1000  loss: 395.360992\n",
            "epoch:   41/1000  loss: 350.028473\n",
            "epoch:   42/1000  loss: 332.371796\n",
            "epoch:   43/1000  loss: 363.214325\n",
            "epoch:   44/1000  loss: 292.468292\n",
            "epoch:   45/1000  loss: 275.134216\n",
            "epoch:   46/1000  loss: 307.865234\n",
            "epoch:   47/1000  loss: 316.977722\n",
            "epoch:   48/1000  loss: 264.009308\n",
            "epoch:   49/1000  loss: 260.817169\n",
            "epoch:   50/1000  loss: 301.888641\n",
            "epoch:   51/1000  loss: 259.734131\n",
            "epoch:   52/1000  loss: 296.085327\n",
            "epoch:   53/1000  loss: 235.837540\n",
            "epoch:   54/1000  loss: 260.957794\n",
            "epoch:   55/1000  loss: 246.877838\n",
            "epoch:   56/1000  loss: 236.610123\n",
            "epoch:   57/1000  loss: 225.950027\n",
            "epoch:   58/1000  loss: 214.080933\n",
            "epoch:   59/1000  loss: 230.929230\n",
            "epoch:   60/1000  loss: 225.211563\n",
            "epoch:   61/1000  loss: 227.411835\n",
            "epoch:   62/1000  loss: 207.848068\n",
            "epoch:   63/1000  loss: 236.809113\n",
            "epoch:   64/1000  loss: 214.144165\n",
            "epoch:   65/1000  loss: 198.668167\n",
            "epoch:   66/1000  loss: 228.741028\n",
            "epoch:   67/1000  loss: 205.933121\n",
            "epoch:   68/1000  loss: 188.222137\n",
            "epoch:   69/1000  loss: 212.639526\n",
            "epoch:   70/1000  loss: 175.810791\n",
            "epoch:   71/1000  loss: 191.867783\n",
            "epoch:   72/1000  loss: 199.173813\n",
            "epoch:   73/1000  loss: 189.376282\n",
            "epoch:   74/1000  loss: 199.025452\n",
            "epoch:   75/1000  loss: 193.321411\n",
            "epoch:   76/1000  loss: 173.521255\n",
            "epoch:   77/1000  loss: 186.413284\n",
            "epoch:   78/1000  loss: 162.370865\n",
            "epoch:   79/1000  loss: 169.138458\n",
            "epoch:   80/1000  loss: 193.941406\n",
            "epoch:   81/1000  loss: 188.286652\n",
            "epoch:   82/1000  loss: 150.003235\n",
            "epoch:   83/1000  loss: 175.516418\n",
            "epoch:   84/1000  loss: 160.522308\n",
            "epoch:   85/1000  loss: 183.666916\n",
            "epoch:   86/1000  loss: 172.285614\n",
            "epoch:   87/1000  loss: 169.176132\n",
            "epoch:   88/1000  loss: 145.089523\n",
            "epoch:   89/1000  loss: 162.908417\n",
            "epoch:   90/1000  loss: 167.149124\n",
            "epoch:   91/1000  loss: 154.203140\n",
            "epoch:   92/1000  loss: 157.211426\n",
            "epoch:   93/1000  loss: 159.380844\n",
            "epoch:   94/1000  loss: 140.802048\n",
            "epoch:   95/1000  loss: 159.111572\n",
            "epoch:   96/1000  loss: 157.573151\n",
            "epoch:   97/1000  loss: 148.531403\n",
            "epoch:   98/1000  loss: 154.137466\n",
            "epoch:   99/1000  loss: 141.811691\n",
            "epoch:  100/1000  loss: 141.669128\n",
            "epoch:  101/1000  loss: 160.379944\n",
            "epoch:  102/1000  loss: 149.097305\n",
            "epoch:  103/1000  loss: 134.816208\n",
            "epoch:  104/1000  loss: 158.222641\n",
            "epoch:  105/1000  loss: 129.891403\n",
            "epoch:  106/1000  loss: 141.845978\n",
            "epoch:  107/1000  loss: 144.059448\n",
            "epoch:  108/1000  loss: 158.806686\n",
            "epoch:  109/1000  loss: 137.997452\n",
            "epoch:  110/1000  loss: 132.852997\n",
            "epoch:  111/1000  loss: 141.931290\n",
            "epoch:  112/1000  loss: 131.687988\n",
            "epoch:  113/1000  loss: 150.278198\n",
            "epoch:  114/1000  loss: 128.498825\n",
            "epoch:  115/1000  loss: 139.068817\n",
            "epoch:  116/1000  loss: 148.501892\n",
            "epoch:  117/1000  loss: 128.528305\n",
            "epoch:  118/1000  loss: 131.127029\n",
            "epoch:  119/1000  loss: 135.125366\n",
            "epoch:  120/1000  loss: 137.985870\n",
            "epoch:  121/1000  loss: 135.915771\n",
            "epoch:  122/1000  loss: 139.657166\n",
            "epoch:  123/1000  loss: 122.825371\n",
            "epoch:  124/1000  loss: 125.736832\n",
            "epoch:  125/1000  loss: 126.626083\n",
            "epoch:  126/1000  loss: 131.366486\n",
            "epoch:  127/1000  loss: 125.271202\n",
            "epoch:  128/1000  loss: 146.610657\n",
            "epoch:  129/1000  loss: 122.581978\n",
            "epoch:  130/1000  loss: 137.134888\n",
            "epoch:  131/1000  loss: 122.237122\n",
            "epoch:  132/1000  loss: 122.308403\n",
            "epoch:  133/1000  loss: 125.014099\n",
            "epoch:  134/1000  loss: 129.805344\n",
            "epoch:  135/1000  loss: 129.767075\n",
            "epoch:  136/1000  loss: 116.342140\n",
            "epoch:  137/1000  loss: 123.357552\n",
            "epoch:  138/1000  loss: 120.750526\n",
            "epoch:  139/1000  loss: 127.397598\n",
            "epoch:  140/1000  loss: 112.811119\n",
            "epoch:  141/1000  loss: 120.835228\n",
            "epoch:  142/1000  loss: 127.511665\n",
            "epoch:  143/1000  loss: 116.613831\n",
            "epoch:  144/1000  loss: 116.628586\n",
            "epoch:  145/1000  loss: 118.760750\n",
            "epoch:  146/1000  loss: 129.040894\n",
            "epoch:  147/1000  loss: 122.609245\n",
            "epoch:  148/1000  loss: 116.302795\n",
            "epoch:  149/1000  loss: 125.786308\n",
            "epoch:  150/1000  loss: 117.223099\n",
            "epoch:  151/1000  loss: 116.422195\n",
            "epoch:  152/1000  loss: 123.052841\n",
            "epoch:  153/1000  loss: 118.903267\n",
            "epoch:  154/1000  loss: 118.228233\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 테스트\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "with torch.no_grad():\n",
        "  prediction = model(X_valid)\n",
        "  mse = mean_squared_error(y_valid, prediction)\n",
        "  r2 = r2_score(y_valid, prediction)\n",
        "\n",
        "mse, r2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5glhinCABdH",
        "outputId": "30e3cb06-951d-4065-9dfc-f8ec88e977c3"
      },
      "execution_count": 381,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(98.112915, -0.2637001309392699)"
            ]
          },
          "metadata": {},
          "execution_count": 381
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "확실히 학습이 덜 되는 모습을 볼 수 있다... 너무 성능이 떨어지네. 적당한 지점을 찾는게 능력일 듯 하다. "
      ],
      "metadata": {
        "id": "NiBEUUYVBj9m"
      }
    }
  ]
}