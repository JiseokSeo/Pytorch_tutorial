{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 파이토치 과적합 방지를 위한 방법들 \n",
        "1. weight decay (가중치 감소)\n",
        "2. dropout (드롭아웃)\n",
        "3. early stopping (조기 종료)"
      ],
      "metadata": {
        "id": "Y6Fa2qaJhwkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "Hnacqk47i4l5"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "X_train = pd.read_excel(\"https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/MouseProtein/mouse_protein_X.xls\", header=None)\n",
        "y_train = pd.read_excel(\"https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/MouseProtein/mouse_protein_label.xls\", header=None)\n",
        "\n",
        "X_train = torch.Tensor(X_train.values)\n",
        "y_train = torch.Tensor(y_train.values)\n"
      ],
      "metadata": {
        "id": "FhUdGIagjAkJ"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 파이토치 튜토리얼을 위한 기본 모델\n",
        "class PytorchBaselineModel(nn.Module):\n",
        "  def __init__(self, input_dim):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(input_dim, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.linear(x)\n",
        "    x = self.sigmoid(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "FjcFApzni0YK"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 선언\n",
        "input_dim = X_train.shape[1]\n",
        "model = PytorchBaselineModel(input_dim)"
      ],
      "metadata": {
        "id": "cF9eUA5WjJaM"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 파라미터 선언\n",
        "epochs = 10000\n",
        "optimizer = optim.Adam(params=model.parameters(),\n",
        "                       lr=0.1)"
      ],
      "metadata": {
        "id": "xTkyrHuvi2-S"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. weight decay  \n",
        "가중치 값이 너무 커지지 않도록 손실함수나 옵티마이저에 규제항을 추가함\n",
        "\n",
        "1. L1 규제 : 가중치 w들의 절대값 합계를 비용 함수에 추가\n",
        "\n",
        "2. L2 규제 : 모든 가중치 w들의 제곱합을 비용 함수에 추가  "
      ],
      "metadata": {
        "id": "otqBuIWOh9x6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "yXCklVIChZWV"
      },
      "outputs": [],
      "source": [
        "# 'weight_decay'을 옵티마이저에 추가한다 (l2노름이 디폴트)\n",
        "optimizer = optim.Adam(params=model.parameters(),\n",
        "                       lr=0.1,\n",
        "                       weight_decay=1e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. dropout\n"
      ],
      "metadata": {
        "id": "5DhWnjaUkqWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 파이토치 튜토리얼을 위한 기본 모델\n",
        "class PytorchBaselineModel(nn.Module):\n",
        "  def __init__(self, input_dim):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(input_dim, 1)\n",
        "    self.dropout = nn.Dropout(0.25)  # 드롭아웃 시킬 비율\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.linear(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.sigmoid(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "QFk_nevJ3V7A"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. early stopping\n",
        "파이토치는 케라스와 다르게 조기종료 기능을 직접 제공하지 않는다  \n",
        "class로 구현해야 한다! "
      ],
      "metadata": {
        "id": "O51U99Pi3tz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 조기종료 클래스\n",
        "class EarlyStopping:\n",
        "  def __init__(self, patience=5):\n",
        "    self.loss = np.inf\n",
        "    self.patience = 0\n",
        "    self.patience_limit = patience\n",
        "        \n",
        "  def step(self, loss):\n",
        "    if self.loss > loss:\n",
        "      self.loss = loss\n",
        "      self.patience = 0\n",
        "    else:\n",
        "      self.patience += 1\n",
        "  \n",
        "  def is_stop(self):\n",
        "    return self.patience >= self.patience_limit"
      ],
      "metadata": {
        "id": "RWxjqAvs3wwZ"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 파라미터 설정\n",
        "epochs = 10000\n",
        "optimizer = optim.Adam(model.parameters(),\n",
        "                       lr=0.001)"
      ],
      "metadata": {
        "id": "3eC4BWmc6V8K"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 조기종료가 들어간 학습과정\n",
        "early_stop = EarlyStopping(patience=5)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  hypothesis = model(X_train)\n",
        "  loss = F.mse_loss(hypothesis, y_train)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "\n",
        "  early_stop.step(loss.item())\n",
        "  if early_stop.is_stop():\n",
        "    break\n",
        "\n",
        "  optimizer.step()\n",
        "\n",
        "  print(f'Epoch {epoch:4d}/{epochs} Cost: {loss.item()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScV_SVWF5i13",
        "outputId": "f4812141-f987-4787-fa8c-a1dbd897db36"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/10000 Cost: 0.47075343132019043\n",
            "Epoch    1/10000 Cost: 0.47075343132019043\n",
            "Epoch    2/10000 Cost: 0.47075343132019043\n",
            "Epoch    3/10000 Cost: 0.47075340151786804\n",
            "Epoch    4/10000 Cost: 0.47075334191322327\n",
            "Epoch    5/10000 Cost: 0.47075334191322327\n",
            "Epoch    6/10000 Cost: 0.4707533121109009\n",
            "Epoch    7/10000 Cost: 0.4707533121109009\n",
            "Epoch    8/10000 Cost: 0.4707532823085785\n",
            "Epoch    9/10000 Cost: 0.4707532823085785\n",
            "Epoch   10/10000 Cost: 0.4707532823085785\n",
            "Epoch   11/10000 Cost: 0.4707532823085785\n",
            "Epoch   12/10000 Cost: 0.4707532823085785\n",
            "Epoch   13/10000 Cost: 0.4707532525062561\n",
            "Epoch   14/10000 Cost: 0.4707532525062561\n",
            "Epoch   15/10000 Cost: 0.4707532525062561\n",
            "Epoch   16/10000 Cost: 0.4707532525062561\n",
            "Epoch   17/10000 Cost: 0.4707532525062561\n",
            "Epoch   18/10000 Cost: 0.4707532227039337\n",
            "Epoch   19/10000 Cost: 0.4707532227039337\n",
            "Epoch   20/10000 Cost: 0.4707532227039337\n",
            "Epoch   21/10000 Cost: 0.4707532227039337\n",
            "Epoch   22/10000 Cost: 0.4707532227039337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gfF7r3vU5_1F"
      },
      "execution_count": 68,
      "outputs": []
    }
  ]
}